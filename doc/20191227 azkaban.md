---
title: 20191227 azkaban
date:  2019-12-27
---

# azkaban

[TOC]

## azkaban 概述

与 ooize 的功能类似，可视化 Web 界面，用于提交任务工作流，支持定时调度

### azkaban 定义

Azkaban是由Linkedin公司推出的一个批量工作流任务调度器，主要用于在一个工作流内以一个特定的顺序运行一组工作和流程，它的配置是通过简单的key:value对的方式，通过配置中的 `dependencies`  来设置依赖关系。Azkaban使用 `job` 配置文件建立任务之间的依赖关系，并提供一个易于使用的web用户界面维护和跟踪你的工作流。

### azkaban 架构

![](http://img.zwer.xyz/blog/20191227165411.png)

- AzkabanWebServer：AzkabanWebServer是整个Azkaban工作流系统的主要管理者，它用户登录认证、负责project管理、定时执行工作流、跟踪工作流执行进度等一系列任务。

- AzkabanExecutorServer：负责具体的工作流的提交、执行，它们通过mysql数据库来协调任务的执行。

- 关系型数据库（MySQL）：存储大部分执行流状态，AzkabanWebServer和AzkabanExecutorServer都需要访问数据库。



### 常规业务日志分析流程

1) 通过Hadoop先将原始数据上传到HDFS上（HDFS的操作）；

2) 使用MapReduce对原始数据进行清洗（MapReduce的操作）；

3) 将清洗后的数据导入到hive表中（hive的导入操作）；

4) 对Hive中多个表的数据进行JOIN处理，得到一张hive的明细表（创建中间表）；

5) 通过对明细表的统计和分析，得到结果报表信息（hive的查询操作）；

![](http://img.zwer.xyz/blog/20191227164813.png)







## azKaban 安装

### 解压到指定目录中，并重命名

```shell
tar xf  azkaban-web-server-2.5.0.tar.gz -C /opt/module/azkaban/
tar xf  azkaban-executor-server-2.5.0.tar.gz -C /opt/module/azkaban/
tar xf azkaban-sql-script-2.5.0.tar.gz -C /opt/module/azkaban/

mv azkaban-web-2.5.0/ server
mv azkaban-executor-server-2.5.0/ executor
```

### SSL 配置

> Keytool是java数据证书的管理工具，使用户能够管理自己的公/私钥对及相关证书。
>
> -keystore  指定密钥库的名称及位置(产生的各类信息将存在.keystore文件中)
>
> -genkey(或者-genkeypair)   生成密钥对
>
> -alias  为生成的密钥对指定别名，如果没有默认是mykey
>
> -keyalg 指定密钥的算法 RSA/DSA 默认是DSA

1. 生成 keystore的密码及相应信息的密钥库

    ```
    keytool -keystore keystore -alias jetty -genkey -keyalg RSA
    ```

    ![](http://img.zwer.xyz/blog/20191227174207.png)

    注意：

    密钥库的密码至少必须6个字符，可以是纯数字或者字母或者数字和字母的组合等等

    密钥库的密码最好和`<jetty>` 的密钥相同，方便记忆

2. 将keystore 拷贝到 azkaban web服务器根目录中

    ```
    [atguigu@hadoop102 azkaban]$ mv keystore /opt/module/azkaban/server/
    ```

### 时间同步

```shell
tzselect
```

### 修改 WebServer 和 Executor 配置文件

- server 下的 conf/azkaban.properties 文件

  ```shell
  #Azkaban Personalization Settings
  #服务器UI名称,用于服务器上方显示的名字
  azkaban.name=Test
  #描述
  azkaban.label=My Local Azkaban
  #UI颜色
  azkaban.color=#FF3601
  azkaban.default.servlet.path=/index
  #默认web server存放web文件的目录
  web.resource.dir=/opt/module/azkaban/server/web/
  #默认时区,已改为亚洲/上海 默认为美国
  default.timezone.id=Asia/Shanghai
  
  #Azkaban UserManager class
  user.manager.class=azkaban.user.XmlUserManager
  #用户权限管理默认类（绝对路径）
  user.manager.xml.file=/opt/module/azkaban/server/conf/azkaban-users.xml
  
  #Loader for projects
  #global配置文件所在位置（绝对路径）
  executor.global.properties=/opt/module/azkaban/executor/conf/global.properties
  azkaban.project.dir=projects
  
  #数据库类型
  database.type=mysql
  #端口号
  mysql.port=3306
  #数据库连接IP
  mysql.host=hadoop102
  #数据库实例名
  mysql.database=azkaban
  #数据库用户名
  mysql.user=root
  #数据库密码
  mysql.password=000000
  #最大连接数
  mysql.numconnections=100
  
  # Velocity dev mode
  velocity.dev.mode=false
  
  # Azkaban Jetty server properties.
  # Jetty服务器属性.
  #最大线程数
  jetty.maxThreads=25
  #Jetty SSL端口
  jetty.ssl.port=8443
  #Jetty端口
  jetty.port=8081
  #SSL文件名（绝对路径）
  jetty.keystore=/opt/module/azkaban/server/keystore
  #SSL文件密码
  jetty.password=000000
  #Jetty主密码与keystore文件相同
  jetty.keypassword=000000
  #SSL文件名（绝对路径）
  jetty.truststore=/opt/module/azkaban/server/keystore
  #SSL文件密码
  jetty.trustpassword=000000
  
  # Azkaban Executor settings
  executor.port=12321
  
  # mail settings
  mail.sender=
  mail.host=
  job.failure.email=
  job.success.email=
  
  lockdown.create.projects=false
  
  cache.directory=cache
  ```

- server 下的 azkaban-user.xml

  添加新用户 admin， 密码也为 admin

  ```xml
  <user username="azkaban" password="azkaban" roles="admin" groups="azkaban" />
  	<user username="metrics" password="metrics" roles="metrics"/>
  	<user username="admin" password="admin" roles="admin,metrics"/>
  	<role name="admin" permissions="ADMIN" />
  	<role name="metrics" permissions="METRICS"/>
  </azkaban-users>
  ```

- executor 下的 conf/azkaban.conf 文件

  ```shell
  #Azkaban
  #时区
  default.timezone.id=Asia/Shanghai
  
  # Azkaban JobTypes Plugins
  #jobtype 插件所在位置
  azkaban.jobtype.plugin.dir=plugins/jobtypes
  
  #Loader for projects
  executor.global.properties=/opt/module/azkaban/executor/conf/global.properties
  azkaban.project.dir=projects
  
  database.type=mysql
  mysql.port=3306
  mysql.host=hadoop102
  mysql.database=azkaban
  mysql.user=root
  mysql.password=000000
  mysql.numconnections=100
  
  # Azkaban Executor settings
  #最大线程数
  executor.maxThreads=50
  #端口号(如修改,请与web服务中一致)
  executor.port=12321
  #线程数
  executor.flow.threads=30
  ```

### 启动 Executor 和 WebServer 

```
# 进入 executor 目录下
bin/azkaban-executor-start.sh

# 进入 server 目录下
bin/azkaban-web-start.sh
```

注意事项：

<font color='red'>先执行executor，再执行web，避免Web Server会因为找不到执行器启动失败。</font>

### 访问浏览器测试

登录的用户名和密码都是 `admin`

```
https://node01:8443/
```

注意： 前缀 https://  一定要加上，若没有加上则会访问不到页面，而且 Linux 的客户端控制端会报 `Unrecognized SSL message, plaintext connection?` 错误。



## azkaban 实战

Azkakaban 内置的任务类型 command 、 java

### 单一 Job 任务

创建 firt.job 文件， 文件后缀名一定要以 `.job` 结尾

```sh
type=command
command echo 'Hello Azkaban'
```

将 first.job 文件打包成 zip 格式，然后通过 Azkaban 的 WebUI 上

### 多个 Job 任务

- first.job

  ```shell
  type=command
  command echo "this is first start job --> {pwd}"
  ```
  
- second.job

  ```shell
  type=command
  dependencies first
  command echo "this is second start job 1"
  ```

- third.job

  ```shell
  type=command
  dependencies first
  command echo "this is second start job 2"
  ```

- fourth.job

  ```shell
  type=command
  dependencies second,third
command echo "this is last start job"
  ```
  

将上述四个 .job 文件打成 一个zip 压缩包，然后通过 Azkaban 的 WebUI 上传到 Azkaban 中

job 之间的依赖关系图

![](http://img.zwer.xyz/blog/20191227210049.png)



### Java 操作任务

创建 javajob.job 文件

```shell
type=javaprocess
java.class=com.szxy.azkaban.MyJavaJob
classpath=./azkabandemo-1.0-SNAPSHOT.jar
```

这里的 classpath  后面的 jar 路径位置相对 job 位置而言的，若 .job 文件跟 .jar 不在同一个 zip 包中， classpath 后面的 jar 路径填写绝对路径

### HDFS 操作

创建 hdfs.job 文件，书写命令，打包 zip 压缩包上传到 Azkaban

```shell
type=command
command hdfs dfs -ls /
```

### MapReduce 任务提交

创建 mr.job 文件， 书写命令，打包 zip 压缩包上传到 AzKaban 

```shell
type=command
command /opt/sxt/hadoop-2.6.5/bin/hadoop jar /opt/sxt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar wordcount /user/root/test.txt /data/wc/outputAzbakaban
```

### Hive 脚本提交

创建 hive.job 文件，书写命令，打包 zip 压缩包上传到 Azkaban

```shell
type=command
# hive job
command  /opt/sxt/apache-hive-1.2.1-bin/bin/hive -e "select * from psn"
```

<font color="red">注意：</font>

<font color="red">直接写hive 命令会导致 azkaban 不能识别，必须要写 hive 的绝对路径才可以</font>

### shell 脚本提交

- hivetest.sh

    ```shell
    /opt/sxt/apache-hive-1.2.1-bin/bin/hive -e "select * from psn"
    ```

- hiveshell.job

  ```shell
  type=command
  command=sh /root/hiveshell/hivetest.sh
  ```


### 总结

hadoop 命令、hive 命令都需要写绝对路径，否则 azkaban 会执行报错。

尤其注意在写 shell 中，使用 hive 命令也需要写绝对路径。


```

```