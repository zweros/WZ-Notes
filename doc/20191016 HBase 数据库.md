---
2title: 20191016 HBase
date: 2019-10-16
---

## HBase 简介

> Hadoop Database，是一个高可靠性、高性能、**面向列**、可伸缩、实时读写的分布式**数据库**

**作用**：主要用来存储非结构化和半结构化的松散数据（列存 NoSQL 数据库）

利用 Hadoop HDFS 作为其文件存储系统,

利用 Hadoop MapReduce 来处理 HBase 中的海量数据,

利用 Zookeeper 作为其分布式协同服务

- 非关系型数据库知识面扩展

  - Cassandra hbase mongodb 
  - Couchdb，文件存储数据库
  - Neo4j非关系型图数据库
- HBase 官网地址：http://hbase.apache.org/

### Hadoop 生态系统  

Hadoop 

![](http://img.zwer.xyz/blog/20191016145209.png)

*MapReduce 计算的数据来源：*

 1. HDFS 或者其他文件系统 2.数据库（既可以是关系型数据也可以非关系型）

*Hive 和 HBase 的区别：*

 Hive 是数据仓库，HBase 是数据库。Hive 是用 SQL 方式处理数据，底层使用 MapReduce 计算框架

*使用 MapReduce  注意：*

1. map 生成小文件  2. 数据倾斜

## HBase 数据模型

![](http://img.zwer.xyz/blog/20191016162050.png)




- **ROW  KEY**（ROW KEY 设计很重要）

  决定一行数据，按照**字典顺序**排序的。Row key只能存储 64k 的字节数据
  
- **Column Family 列族 & qualifier列**

  1. HBase 表中的每个列都归属于某个列族，列族必须作为表模式(schema)定义的一部分预先给出。

     如 create ‘test’, ‘course’；

  2. 列名以列族作为前缀，每个“列族”都可以有多个列成员(column)；

     如course:math, course:english, 新的列族成员（列）可以随后按需、动态加入；

  3. 权限控制、存储以及调优都是在列族层面进行的；

  4. HBase 把同一列族里面的数据存储在同一目录下，由几个文件保存。
  
- **Cell 单元格**

  由行和列的坐标交叉决定；

  单元格是有版本的；

  单元格的内容是未解析的*字节数组*；

  由`{row key， column( =<family> +<qualifier>)， version}` 唯一确定的单元。

  cell中的数据是没有类型的，全部是*字节码形式存贮*。

- **Timestamp 时间戳**

  在 HBase 每个 cell 存储单元对同一份数据有多个版本，根据唯一的时间戳来区分每个版本之间的差异，不同版本的数据按照时间倒序排序，最新的数据版本排在最前面。

  时间戳的类型是 64位整型。

  时间戳可以由 HBase (在数据写入时自动)赋值，此时时间戳是精确到毫秒的当前系统时间。

  时间戳也可以由客户显式赋值，如果应用程序要避免数据版本冲突，就必须自己生成具有唯一性的时间戳。

- **HLog(WAL log)**

  HLog 文件就是一个普通的 Hadoop Sequence File，Sequence File 的 Key 是 HLogKey 对象，HLogKey 中记录了写入数据的归属信息，除了 table 和 region 名字外，同时还包括 sequence number 和 timestamp，timestamp 是” 写入时间”，sequence number 的起始值为0，或者是最近一次存入文件系统中 sequence number。
  HLog SequeceFile 的 Value 是 HBase 的 KeyValue 对象，即对应 HFile 中的 KeyValue。

注：region：范围、地区

## HBase 架构

### HBase 架构图

![](http://img.zwer.xyz/blog/20191016162618.png)

### HBase 架构中各角色作用

- **Client**
  包含访问 HBase 的接口并维护 cache 来加快对 HBase 的访问

- **Zookeeper**（不仅可以做集群的高可用）
  保证任何时候，集群中只有一个 master
  存储所有 Region 的寻址入口。
  实时监控 Region server 的上线和下线信息。并实时通知 Master
  存储 HBase 的 schema 和 table 元数据

- **Master**
  为 Region server 分配 region
  负责 Region server 的负载均衡
  发现失效的 Region server 并重新分配其上的 region
  管理用户对 table 的增删改操作

- **RegionServer**
  Region server 维护 region，处理对这些 region 的 IO 请求
  Region server 负责切分在运行过程中变得过大的 region

- **Region**
  HBase 自动把表水平划分成多个区域(region)，每个 region 会保存一个表里面某段*连续的数据*（按字典序）

  每个表一开始只有一个 region，随着数据不断插入表，region 不断增大，当增大到一个阀值的时候，region就会等分会两个新的 region（裂变）

  当 table 中的行不断增多，就会有越来越多的 region。这样一张完整的表被保存在多个 Regionserver 上。

- **Memstore & storefile**
  一个 region 由多个 store 组成，一个 store 对应一个CF（列族）
  
  store 包括位于内存中的 memstore 和位于磁盘的 storefile 。
  
  写操作先写入memstore，当 memstore 中的数据达到某个阈值，hregionserver 会启动 flashcache 进程写

  入 storefile，每次写入形成单独的一个 storefile。
  
  当 storefile 文件的数量增长到一定阈值后，**系统会进行合并（minor、major compaction）**，在合并过程
  
  中会进行版本合并和删除工作（majar），形成更大的 storefile。
  
  当一个 region 所有 storefile的大小和数量超过一定阈值后，会把当前的 region 分割为两个，并由 hmaster
  
  分配到相应的 regionserver 服务器，实现负载均衡。
  
  客户端检索数据，先在 memstore 找，找不到再找 storefile（先找 cache 后找磁盘）
  
- storefile & hfile

  storefile 是逻辑上， hfile 是物理上

- **Region补充：**

  HRegion 是 HBase 中分布式存储和负载均衡的最小单元。

  最小单元就表示不同的 HRegion 可以分布在不同的 HRegion server上。

  HRegion 由一个或者多个 Store 组成，每个 store 保存一个 columns family。

  每个 Strore 又由一个 memStore 和 0 至多个 StoreFile 组成。

  如图：StoreFile 以 HFile 格式保存在 HDFS上。

  <img src="http://img.zwer.xyz/blog/20191016164827.png" style="zoom: 50%;" />

  <img src="http://img.zwer.xyz/blog/20191016165005.png" style="zoom:50%;" />

## HBase 环境搭建

HBase 官方文档地址：http://hbase.apache.org/book.html#quickstart

### HBase 伪分布式搭建

- **系统环境**

  JDK  1.7，并配置 JAVA_HOME 环境变量

- **HBase 安装步骤**

  ```shell
  # 上传 HBase 压缩包文件，并解压到指定目录， 通过 tar 命令中 -C 指定解压到的目录
  tar xf hbase-0.98.12.1-hadoop2-bin.tar.gz  -C  /opt/sxt
  
  # 配置 HBase 环境变量
  vi /etc/profile
  # 增加的配置内容
  export HBASE_HOME=/opt/sxt/hbase-0.98.12.1-hadoop2
  export PATH=$PATH:$JAVA_HOME/bin:$HBASE_HOME/bin
  # 环境变量生效
  . /etc/profile
  
  # 进入 $HBSE_HOME/conf 下
  # 修改 hbase-env.sh
  export JAVA_HOME=/usr/java/jdk1.7.0_67
  
  # 修改 hbase-site.xml 
  <property>
  <name>hbase.rootdir</name>
  <value>file:///home/testuser/hbase</value>
  </property>
  <property>
  <name>hbase.zookeeper.property.dataDir</name>
  <value>/home/testuser/zookeeper</value>
  </property>
  <property>
  <name>hbase.unsafe.stream.capability.enforce</name>
  <value>false</value>
  </property>
  
  # 启动
  start-hbase.sh
  # 访问 HBase ，端口号为 60010
  http://192.168.170.105:60010
  # 
  hbase shell
  #help 查看 hbase 使用
  #list  列出所欲当前数据表
  #scan  列出当前数据表中记录数
  #create 创建表
  #put    增加记录
  #delete  删除记录
  ```
  
- **HBase 操作**

![](http://img.zwer.xyz/blog/20191016204121.png)

补充：  list  显示当前 HBase 中所有表  

​			  flush 将 inmemstore 中数据写入 storefile 

### HBase 完全分布式搭建

- **节点分布**

  |        |  NN  |  DN  |  ZK  | HMaster | Backup-HMaster | RegionServer |
  | :----: | :--: | :--: | :--: | :-----: | :------------: | :----------: |
  | node01 |  *   |      |      |    *    |                |              |
  | node02 |      |  *   |  *   |         |                |      *       |
  | node03 |      |  *   |  *   |         |                |      *       |
  | node04 |      |  *   |  *   |         |                |      *       |
  | node05 |      |      |      |         |       *        |              |

- **系统设置**

  1. 集群间网络通信

  2. 时间同步

     ```shell
     # 安装 ntp 服务
     yum install -y ntp
     # 时间服务器
     ntpdate ntp1.aliyun.com
     ```

  3. JDK 环境

  4. 免秘钥登录

     ```shell
     ssh-keygen
     ssh-copy-id -i /root/.ssh/id_rsa.pub host(需要免密钥登录的服务器地址)
     eg: ssh-copy-id -i .ssh/id_rsa.pub  node02
     ```

  5. hadoop 集群启动

     ```
     start-dfs.sh
     ```

- **HBase 搭建**

  1. 上传解压

  2. 修改配置文件

     ```shell
     # node 节点上------------------------------
     # 进入 $HBASE_HOME/conf 目录下
     # 编辑 vi  hbase-env.sh ,配置JDk 、关闭 zk 
     export JAVA_HOME=/usr/java/jdk1.7.0_67
     export HBASE_MANAGES_ZK=false
     
     # 编辑 vi hbase-site.xml ，增加内容为 
     <property>
       <name>hbase.cluster.distributed</name>
       <value>true</value>
     </property>
     <property>
       <name>hbase.rootdir</name>
       <value>hdfs://mycluster:8020/hbase</value>
     </property>
     <property>
       <name>hbase.zookeeper.quorum</name>
       <value>node02,node03,node04</value>
     </property>
     
     # 编辑 vi regionservers,增加内容为 
     node02
     node03
     node04
     # 编辑 vi backup-masters，增加内容为 
     node05
     # 拷贝 $HADOOP_HOME/etc/hadoop/hdfs-size.xml 到 $HBASE_HOME/conf 目录下(重要)
     
     # 分发到 node02、node03、node04、node05
     
     # 配置 node02、node03、node04、node05 的 hbase 环境变量
     ```

  3. **启动**

     ```shell
     start-hbase.sh
     ```

     ![](http://img.zwer.xyz/blog/20191016213051.png)



## HBase-API

> 重点 ： rowkey 设计

### Demo

1. 创建 hbase-demo 普通 java 项目，并导入 hadoop 和 hbase 相关依赖 jar 包，并发布到类路径上

2. 创建 HBaseDemo

```java
public class HbaseDemo {

	HBaseAdmin admin;
	HTable htable;
	Configuration conf;
	String TN = "test";

	@Before
	public void init() throws Exception {
		conf = new Configuration();
		conf.set("hbase.zookeeper.quorum", "node02,node03,node04");
		admin = new HBaseAdmin(conf);
		htable = new HTable(conf, TN.getBytes());
	}
    
    	@After
	public void close() throws Exception {
		if (admin != null) {
			admin.close();
		}
    }
}
```

- 创建表

```java
@Test
public void createTable() throws Exception {
    HTableDescriptor table = new HTableDescriptor(TableName.valueOf(TN.getBytes()));
    HColumnDescriptor column = new HColumnDescriptor("cf");
    table.addFamily(column);
    if (admin.tableExists(TN.getBytes())) {
        admin.disableTable(TN.getBytes());
        admin.deleteTable(TN.getBytes());
    }
    admin.createTable(table);
}

```

- 存放数据

```java
public void put() throws Exception {
		String rowkey = "r124";
		Put put = new Put(rowkey.getBytes());
		put.add("cf".getBytes(), "name".getBytes(), "xiaoli".getBytes());
		put.add("cf".getBytes(), "age".getBytes(), "32".getBytes());
		put.add("cf".getBytes(), "sex".getBytes(), "female".getBytes());
		htable.put(put);
}
```

- 获取数据

```java
@Test
public void showTable() throws Exception {
    Get get = new Get("r123".getBytes());
    // 必须加
    get.addColumn("cf".getBytes(), "name".getBytes());
    get.addColumn("cf".getBytes(), "age".getBytes());
    Result result = htable.get(get);
    Cell name = result.getColumnLatestCell("cf".getBytes(), "name".getBytes());
    Cell age = result.getColumnLatestCell("cf".getBytes(), "age".getBytes());
    // System.out.println(new String(name.getValue()));
    // System.out.println(new String(age.getValue()));
    System.out.print(new String(CellUtil.cloneValue(name)));
    System.out.print(new String(CellUtil.cloneValue(age)));
}

```

- 条件查询

```java
	
	/**
	 * 生成电话号码
	 * @param prefix
	 * @return
	 */
	Random r = new Random();
	private String generatePhoneNumber(String prefix) {
		String pNum = prefix + String.format("%08d", r.nextInt(99999999));
		return pNum;
	}

	/**
	 *  获取随机时间
	 */
	DateFormat sdf = new SimpleDateFormat("yyyyMMddHHmmss");
	public String getDate(String year) {
		// 月 天 小时 分钟 秒
		Object[] args = { r.nextInt(12)+1, r.nextInt(31)+1, r.nextInt(24), r.nextInt(60), r.nextInt(60) };
		String dateStr = year + String.format("%02d%02d%02d%02d%02d", args);
		return dateStr;
	}
	
	/**
	 *  生成 10个人通话记录
	 *  // phoneNum_(max-timestamp)  
	 */
	@Test
	public void addPhoneRecord() throws Exception{
		List<Put> puts = new ArrayList<>();
		for(int i = 0;i < 10;i++){
			String phoneNum = generatePhoneNumber("189");
			for(int j = 0;j < 100;j++){
				String dnum = generatePhoneNumber("138");
				String length = r.nextInt(99)+""; // 通话时长
				String type = r.nextInt(2)+""; // 1 是主叫，2 是被叫
				String dataStr  = getDate("2019");  // 通话开始时间
				String rowkey = phoneNum+"_"+(Long.MAX_VALUE-sdf.parse(dataStr).getTime());
				Put put = new Put(rowkey.getBytes());
				put.add("cf".getBytes(),"dnum".getBytes(),dnum.getBytes());
				put.add("cf".getBytes(),"length".getBytes(),length.getBytes());
				put.add("cf".getBytes(),"type".getBytes(),type.getBytes());
				put.add("cf".getBytes(),"dataStr".getBytes(),dataStr.getBytes());
				puts.add(put);
			}
		}
		htable.put(puts);
	}

	/**
	 * 查找通话记录 ，指定电话的在 1月份 4 月份之间的通话记录
	 */
	@Test
	public void scan() throws Exception {
		String phoneNum = "18985484208";                            //20190022203207
		String startRow = phoneNum+"_"+(Long.MAX_VALUE-sdf.parse("20190401000000").getTime());
		String stopRow =  phoneNum+"_"+(Long.MAX_VALUE-sdf.parse("20190101000000").getTime());
		Scan scan = new Scan();
		scan.setStartRow(startRow.getBytes());
		scan.setStopRow(stopRow.getBytes());
		ResultScanner scanner = htable.getScanner(scan);
		int count = 0;
		for (Result rs : scanner) {
			System.out.print(new String(CellUtil.cloneValue(rs.getColumnLatestCell("cf".getBytes(), "dnum".getBytes()))));
			System.out.print("\t"+new String(CellUtil.cloneValue(rs.getColumnLatestCell("cf".getBytes(), "length".getBytes()))));
			System.out.print("\t"+new String(CellUtil.cloneValue(rs.getColumnLatestCell("cf".getBytes(), "type".getBytes()))));
			System.out.println("\t"+new String(CellUtil.cloneValue(rs.getColumnLatestCell("cf".getBytes(), "dataStr".getBytes()))));
			count ++;
		}
		System.out.println("count:"+count);
	}

	/**
	 * 查找指定电话主叫的通话记录
	 * @throws Exception
	 */
	@Test
	public void scan2() throws Exception{
		FilterList list = new FilterList(FilterList.Operator.MUST_PASS_ALL);
		PrefixFilter filter1 = new PrefixFilter("18985484208".getBytes());
		SingleColumnValueFilter filter2 = new SingleColumnValueFilter("cf".getBytes(), "type".getBytes(),
				CompareOp.EQUAL, "1".getBytes());
		list.addFilter(filter1);
		list.addFilter(filter2);
		Scan scan = new Scan();
		scan.setFilter(list);
		ResultScanner scanner = htable.getScanner(scan);
		int count = 0;
		for (Result rs : scanner) {
			System.out.print(new String(rs.getRow()));
			System.out.print("\t"+new String(CellUtil.cloneValue(rs.getColumnLatestCell("cf".getBytes(), "dnum".getBytes()))));
			System.out.print("\t"+new String(CellUtil.cloneValue(rs.getColumnLatestCell("cf".getBytes(), "length".getBytes()))));
			System.out.print("\t"+new String(CellUtil.cloneValue(rs.getColumnLatestCell("cf".getBytes(), "type".getBytes()))));
			System.out.println("\t"+new String(CellUtil.cloneValue(rs.getColumnLatestCell("cf".getBytes(), "dataStr".getBytes()))));
			count ++;
		}
		System.out.println("count:"+count);
}
	
```

### 工具类

```java
public class HBaseDAOImp {

	HConnection hTablePool = null;
	static Configuration conf = null;

	public HBaseDAOImp() {
		conf = new Configuration();
		String zk_list = "node01,node02,node03";
		conf.set("hbase.zookeeper.quorum", zk_list);
		try {
			hTablePool = HConnectionManager.createConnection(conf);
		} catch (IOException e) {
			e.printStackTrace();
		}
	}

	public void save(Put put, String tableName) {
		HTableInterface table = null;
		try {
			table = hTablePool.getTable(tableName);
			table.put(put);

		} catch (Exception e) {
			e.printStackTrace();
		} finally {
			try {
				table.close();
			} catch (IOException e) {
				e.printStackTrace();
			}
		}
	}

	/**
	 * 插入一个cell
	 * 
	 * @param tableName
	 * @param rowKey
	 * @param family
	 * @param quailifer
	 * @param value
	 */
	public void insert(String tableName, String rowKey, String family, String quailifer, String value) {
		// TODO Auto-generated method stub
		HTableInterface table = null;
		try {
			table = hTablePool.getTable(tableName);
			Put put = new Put(rowKey.getBytes());
			put.add(family.getBytes(), quailifer.getBytes(), value.getBytes());
			table.put(put);
		} catch (Exception e) {
			e.printStackTrace();
		} finally {
			try {
				table.close();
			} catch (IOException e) {
				e.printStackTrace();
			}
		}
	}

	/**
	 * 在一个列族下插入多个单元格
	 * 
	 * @param tableName
	 * @param rowKey
	 * @param family
	 * @param quailifer
	 * @param value
	 */
	public void insert(String tableName, String rowKey, String family, String quailifer[], String value[]) {
		HTableInterface table = null;
		try {
			table = hTablePool.getTable(tableName);
			Put put = new Put(rowKey.getBytes());
			// 批量添加
			for (int i = 0; i < quailifer.length; i++) {
				String col = quailifer[i];
				String val = value[i];
				put.add(family.getBytes(), col.getBytes(), val.getBytes());
			}
			table.put(put);
		} catch (Exception e) {
			e.printStackTrace();
		} finally {
			try {
				table.close();
			} catch (IOException e) {
				e.printStackTrace();
			}
		}
	}

	public void save(List<Put> Put, String tableName) {
		HTableInterface table = null;
		try {
			table = hTablePool.getTable(tableName);
			table.put(Put);
		} catch (Exception e) {
		} finally {
			try {
				table.close();
			} catch (IOException e) {
				e.printStackTrace();
			}
		}

	}

	public Result getOneRow(String tableName, String rowKey) {
		HTableInterface table = null;
		Result rsResult = null;
		try {
			table = hTablePool.getTable(tableName);
			Get get = new Get(rowKey.getBytes());
			rsResult = table.get(get);
		} catch (Exception e) {
			e.printStackTrace();
		} finally {
			try {
				table.close();
			} catch (IOException e) {
				e.printStackTrace();
			}
		}
		return rsResult;
	}

	/**
	 * 最常用的方法，优化查询 查询一行数据，
	 * 
	 * @param tableName
	 * @param rowKey
	 * @param cols
	 * @return
	 */
	public Result getOneRowAndMultiColumn(String tableName, String rowKey, String[] cols) {
		HTableInterface table = null;
		Result rsResult = null;
		try {
			table = hTablePool.getTable(tableName);
			Get get = new Get(rowKey.getBytes());
			for (int i = 0; i < cols.length; i++) {
				get.addColumn("cf".getBytes(), cols[i].getBytes());
			}
			rsResult = table.get(get);
		} catch (Exception e) {
			e.printStackTrace();
		} finally {
			try {
				table.close();
			} catch (IOException e) {
				e.printStackTrace();
			}
		}
		return rsResult;
	}

	public List<Result> getRows(String tableName, String rowKeyLike) {
		HTableInterface table = null;
		List<Result> list = null;
		try {
			FilterList fl = new FilterList(FilterList.Operator.MUST_PASS_ALL);
			table = hTablePool.getTable(tableName);
			PrefixFilter filter = new PrefixFilter(rowKeyLike.getBytes());
			SingleColumnValueFilter filter1 = new SingleColumnValueFilter("order".getBytes(), "order_type".getBytes(),
					CompareOp.EQUAL, Bytes.toBytes("1"));
			fl.addFilter(filter);
			fl.addFilter(filter1);
			Scan scan = new Scan();
			scan.setFilter(fl);
			ResultScanner scanner = table.getScanner(scan);
			list = new ArrayList<Result>();
			for (Result rs : scanner) {
				list.add(rs);
			}
		} catch (Exception e) {
			e.printStackTrace();
		} finally {
			try {
				table.close();
			} catch (IOException e) {
				e.printStackTrace();
			}
		}
		return list;
	}

	public List<Result> getRows(String tableName, String rowKeyLike, String cols[]) {
		// TODO Auto-generated method stub
		HTableInterface table = null;
		List<Result> list = null;
		try {
			table = hTablePool.getTable(tableName);
			PrefixFilter filter = new PrefixFilter(rowKeyLike.getBytes());

			Scan scan = new Scan();
			for (int i = 0; i < cols.length; i++) {
				scan.addColumn("cf".getBytes(), cols[i].getBytes());
			}
			scan.setFilter(filter);
			ResultScanner scanner = table.getScanner(scan);
			list = new ArrayList<Result>();
			for (Result rs : scanner) {
				list.add(rs);
			}
		} catch (Exception e) {
			e.printStackTrace();
		} finally {
			try {
				table.close();
			} catch (IOException e) {
				e.printStackTrace();
			}
		}
		return list;
	}

	public List<Result> getRowsByOneKey(String tableName, String rowKeyLike, String cols[]) {
		// TODO Auto-generated method stub
		HTableInterface table = null;
		List<Result> list = null;
		try {
			table = hTablePool.getTable(tableName);
			PrefixFilter filter = new PrefixFilter(rowKeyLike.getBytes());

			Scan scan = new Scan();
			for (int i = 0; i < cols.length; i++) {
				scan.addColumn("cf".getBytes(), cols[i].getBytes());
			}
			scan.setFilter(filter);
			ResultScanner scanner = table.getScanner(scan);
			list = new ArrayList<Result>();
			for (Result rs : scanner) {
				list.add(rs);
			}
		} catch (Exception e) {
			e.printStackTrace();
		} finally {
			try {
				table.close();
			} catch (IOException e) {
				e.printStackTrace();
			}
		}
		return list;
	}

	/**
	 * 范围查询
	 * 
	 * @param tableName
	 * @param startRow
	 * @param stopRow
	 * @return
	 */
	public List<Result> getRows(String tableName, String startRow, String stopRow) {
		HTableInterface table = null;
		List<Result> list = null;
		try {
			table = hTablePool.getTable(tableName);
			Scan scan = new Scan();
			scan.setStartRow(startRow.getBytes());
			scan.setStopRow(stopRow.getBytes());
			ResultScanner scanner = table.getScanner(scan);
			list = new ArrayList<Result>();
			for (Result rsResult : scanner) {
				list.add(rsResult);
			}

		} catch (Exception e) {
			e.printStackTrace();
		} finally {
			try {
				table.close();
			} catch (IOException e) {
				e.printStackTrace();
			}
		}
		return list;
	}

	public void deleteRecords(String tableName, String rowKeyLike) {
		HTableInterface table = null;
		try {
			table = hTablePool.getTable(tableName);
			PrefixFilter filter = 
				new PrefixFilter(rowKeyLike.getBytes());
			Scan scan = new Scan();
			scan.setFilter(filter);
			ResultScanner scanner = table.getScanner(scan);
			List<Delete> list = new ArrayList<Delete>();
			for (Result rs : scanner) {
				Delete del = new Delete(rs.getRow());
				list.add(del);
			}
			table.delete(list);
		} catch (Exception e) {
			e.printStackTrace();
		} finally {
			try {
				table.close();
			} catch (IOException e) {
				e.printStackTrace();
			}
		}

	}

	public void deleteCell(String tableName, String rowkey, String cf, String column) {
		HTableInterface table = null;
		try {
			table = hTablePool.getTable(tableName);
			Delete del = new Delete(rowkey.getBytes());
			del.deleteColumn(cf.getBytes(), column.getBytes());
			table.delete(del);
		} catch (Exception e) {
			e.printStackTrace();
		} finally {
			try {
				table.close();
			} catch (IOException e) {
				e.printStackTrace();
			}
		}

	}

	public void createTable(String tableName, String[] columnFamilys) {
		try {
			// admin 对象
			HBaseAdmin admin = new HBaseAdmin(conf);
			if (admin.tableExists(tableName)) {
				System.err.println("此表，已存在！");
			} else {
				HTableDescriptor tableDesc = new HTableDescriptor(TableName.valueOf(tableName));

				for (String columnFamily : columnFamilys) {
					tableDesc.addFamily(new HColumnDescriptor(columnFamily));
				}

				admin.createTable(tableDesc);
				System.err.println("建表成功!");

			}
			admin.close();// 关闭释放资源
		} catch (MasterNotRunningException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		} catch (ZooKeeperConnectionException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		} catch (IOException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}

	}

	/**
	 * 删除一个表
	 * 
	 * @param tableName
	 *            删除的表名
	 */
	public void deleteTable(String tableName) {
		try {
			HBaseAdmin admin = new HBaseAdmin(conf);
			if (admin.tableExists(tableName)) {
				admin.disableTable(tableName);// 禁用表
				admin.deleteTable(tableName);// 删除表
				System.err.println("删除表成功!");
			} else {
				System.err.println("删除的表不存在！");
			}
			admin.close();
		} catch (MasterNotRunningException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		} catch (ZooKeeperConnectionException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		} catch (IOException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}
	}

	/**
	 * 查询表中所有行
	 * 
	 * @param tablename
	 */
	public void scaner(String tablename) {
		try {
			HTable table = new HTable(conf, tablename);
			Scan s = new Scan();
			// s.addColumn(family, qualifier)
			// s.addColumn(family, qualifier)
			ResultScanner rs = table.getScanner(s);
			for (Result r : rs) {

				for (Cell cell : r.rawCells()) {
					System.out.println("RowName:" + new String(CellUtil.cloneRow(cell)) + " ");
					System.out.println("Timetamp:" + cell.getTimestamp() + " ");
					System.out.println("column Family:" + new String(CellUtil.cloneFamily(cell)) + " ");
					System.out.println("row Name:" + new String(CellUtil.cloneQualifier(cell)) + " ");
					System.out.println("value:" + new String(CellUtil.cloneValue(cell)) + " ");
				}
			}
		} catch (IOException e) {
			e.printStackTrace();
		}
	}

	public void scanerByColumn(String tablename) {

		try {
			HTable table = new HTable(conf, tablename);
			Scan s = new Scan();
			s.addColumn("cf".getBytes(), "201504052237".getBytes());
			s.addColumn("cf".getBytes(), "201504052237".getBytes());
			ResultScanner rs = table.getScanner(s);
			for (Result r : rs) {

				for (Cell cell : r.rawCells()) {
					System.out.println("RowName:" + new String(CellUtil.cloneRow(cell)) + " ");
					System.out.println("Timetamp:" + cell.getTimestamp() + " ");
					System.out.println("column Family:" + new String(CellUtil.cloneFamily(cell)) + " ");
					System.out.println("row Name:" + new String(CellUtil.cloneQualifier(cell)) + " ");
					System.out.println("value:" + new String(CellUtil.cloneValue(cell)) + " ");
				}
			}
		} catch (IOException e) {
			e.printStackTrace();
		}
	}

	public static void main(String[] args) {

		// 创建表
		// String tableName="test";
		// String cfs[] = {"cf"};
		// dao.createTable(tableName,cfs);

		// 存入一条数据
		// Put put = new Put("bjsxt".getBytes());
		// put.add("cf".getBytes(), "name".getBytes(), "cai10".getBytes()) ;
		// dao.save(put, "test") ;

		// 插入多列数据
		// Put put = new Put("bjsxt".getBytes());
		// List<Put> list = new ArrayList<Put>();
		// put.add("cf".getBytes(), "addr".getBytes(), "shanghai1".getBytes()) ;
		// put.add("cf".getBytes(), "age".getBytes(), "30".getBytes()) ;
		// put.add("cf".getBytes(), "tel".getBytes(), "13889891818".getBytes())
		// ;
		// list.add(put) ;
		// dao.save(list, "test");

		// 插入单行数据
		// dao.insert("test", "testrow", "cf", "age", "35") ;
		// dao.insert("test", "testrow", "cf", "cardid", "12312312335") ;
		// dao.insert("test", "testrow", "cf", "tel", "13512312345") ;

		// List<Result> list = dao.getRows("test", "testrow",new
		// String[]{"age"}) ;
		// for(Result rs : list)
		// {
		// for(Cell cell:rs.rawCells()){
		// System.out.println("RowName:"+new String(CellUtil.cloneRow(cell))+"
		// ");
		// System.out.println("Timetamp:"+cell.getTimestamp()+" ");
		// System.out.println("column Family:"+new
		// String(CellUtil.cloneFamily(cell))+" ");
		// System.out.println("row Name:"+new
		// String(CellUtil.cloneQualifier(cell))+" ");
		// System.out.println("value:"+new String(CellUtil.cloneValue(cell))+"
		// ");
		// }
		// }

		// Result rs = dao.getOneRow("test", "testrow");
		// System.out.println(new String(rs.getValue("cf".getBytes(),
		// "age".getBytes())));

		// Result rs = dao.getOneRowAndMultiColumn("cell_monitor_table",
		// "29448-513332015-04-05", new
		// String[]{"201504052236","201504052237"});
		// for(Cell cell:rs.rawCells()){
		// System.out.println("RowName:"+new String(CellUtil.cloneRow(cell))+"
		// ");
		// System.out.println("Timetamp:"+cell.getTimestamp()+" ");
		// System.out.println("column Family:"+new
		// String(CellUtil.cloneFamily(cell))+" ");
		// System.out.println("row Name:"+new
		// String(CellUtil.cloneQualifier(cell))+" ");
		// System.out.println("value:"+new String(CellUtil.cloneValue(cell))+"
		// ");
		// }

		// dao.deleteTable("cell_monitor_table");
		// 创建表
		String tableName = "cell_monitor_table";
		String cfs[] = { "cf" };
		// dao.createTable(tableName,cfs);
	}

	public static void testRowFilter(String tableName) {
		try {
			HTable table = new HTable(conf, tableName);
			Scan scan = new Scan();
			scan.addColumn(Bytes.toBytes("column1"), Bytes.toBytes("qqqq"));
			Filter filter1 = new RowFilter(CompareOp.LESS_OR_EQUAL, new BinaryComparator(Bytes.toBytes("laoxia157")));
			scan.setFilter(filter1);
			ResultScanner scanner1 = table.getScanner(scan);
			for (Result res : scanner1) {
				System.out.println(res);
			}
			scanner1.close();

			//
			// Filter filter2 = new RowFilter(CompareFilter.CompareOp.EQUAL,new
			// RegexStringComparator("laoxia4\\d{2}"));
			// scan.setFilter(filter2);
			// ResultScanner scanner2 = table.getScanner(scan);
			// for (Result res : scanner2) {
			// System.out.println(res);
			// }
			// scanner2.close();

			Filter filter3 = new RowFilter(CompareOp.EQUAL, new SubstringComparator("laoxia407"));
			scan.setFilter(filter3);
			ResultScanner scanner3 = table.getScanner(scan);
			for (Result res : scanner3) {
				System.out.println(res);
			}
			scanner3.close();
		} catch (IOException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}
	}

	@Test
	public void testTrasaction() {
		try {
			HTableInterface table = null;
			table = hTablePool.getTable("t_test".getBytes());
			// Put put1 =new Put("002".getBytes());
			// put1.add("cf1".getBytes(), "name".getBytes(), "王五".getBytes());
			// table.put(put1);
			Put newput = new Put("001".getBytes());
			newput.add("cf1".getBytes(), "like".getBytes(), "看书".getBytes());

			boolean f = table.checkAndPut("001".getBytes(), "cf1".getBytes(), "age".getBytes(), "24".getBytes(),
					newput);
			System.out.println(f);

		} catch (Exception e) {
			e.printStackTrace();
		}

	}
}

```



## HBase 微博案例

> 目的：怎么设计 HBase 表以及内部 RowKey 的设计

### 需求

```  
1. 添加、查看关注
2. 粉丝列表
3. 写微博
4. 查看首页， 所有关注过的好友发布的最新微博
5. 查看某个用户发布的所有微博

eg:               关注列表 					粉丝列表
张三001             李四				       王五
李四002                                      张三，王五
王五003  	           张三					  张三

follow_fan
rowkey  		 cf1(关注列表)                cf2(粉丝列表)
001				 002=李四;					   003=王五;
002              	                            001=张三;003=王五                      
003              001=张三;					   001=张三

tb_write_blog
rowkey      					cf1
uid_(Max-timestamp)             cf1:title;cf1:content;

writed_blog_history_version

```

## Protobuf 

> Protocol Buffers 是**一种轻便高效的结构化数据存储格式，可以用于结构化数据串行化，或者说序列化**。

### Protobuf 简介

Google Protocol Buffer( 简称 Protobuf) 是 Google 公司内部的混合语言数据标准。

目前已经正在使用的有超过 48,162 种报文格式定义和超过 12,183 个 .proto 文件。

他们用于 RPC 系统和持续数据存储系统。

Protocol Buffers 是**一种轻便高效的结构化数据存储格式，可以用于结构化数据串行化，或者说序列化**。

它很适合做数据存储或 RPC 数据交换格式。

可用于通讯协议、数据存储等领域的语言无关、平台无关、可扩展的序列化结构数据格式。

目前提供了 C++、Java、Python 三种语言的 API。

### 安装 Google  Protocol Buffer 

```shell
yum groupinstall Development tools -y

tar -xzf protobuf-2.1.0.tar.gz 
# 配置
.cofigure --prefix=/usr/local/protobuf

#编译并安装
make && make install 

#配置环境变量
export PROTOBUF=/usr/local/protobuf
```

### protobuf 的使用

```shell
# 编辑 vi  Phone.proto 文件
package com.szxy.hbase;
message PhoneDetail{
	required string dnum=1;   // 被叫电话
	required string type=2;  // 通话类型
	required string length=3;  // 通话时长
	required string datastr=4; // 通话时间
} 

# 执行 
protoc ./Phone --java_out=./

# 将生成的 java 文件拷贝到本地 Eclipse 上

@Test
	public void addPhoneRecord2() throws Exception{
		List<Put> puts = new ArrayList<>();
		for(int i = 0;i < 10;i++){
			String phoneNum = generatePhoneNumber("189");
			for(int j = 0;j < 100;j++){
				String dnum = generatePhoneNumber("138");
				String length = r.nextInt(99)+""; // 通话时长
				String type = r.nextInt(2)+""; // 1 是主叫，2 是被叫
				String dataStr  = getDate("2019");  // 通话开始时间
				String rowkey =
                phoneNum+"_"+(Long.MAX_VALUE-sdf.parse(dataStr).getTime());
				Builder builder
                = Phone.PhoneDetail.getDefaultInstance().newBuilderForType();
				builder.setDnum(dnum);
				builder.setLength(length);
				builder.setType(type);
				builder.setDatastr(dataStr);
				Put put 
				= new Put(rowkey.getBytes());
			put.add("cf".getBytes(),"phoneDetail".getBytes(),builder.build().toByteArray());
				puts.add(put);
			}
		}
		htable.put(puts);
	}
	
# 编辑 vi  phoneDetail.proto 文件
package com.szxy.hbase;

message PhoneDetail
{
    required string dnum=1;  
    required string type=2; 
    required string length=3; 
    required string datastr=4;
} 
message dayPhoneDetail
{
	repeated PhoneDetail  phoneDetail = 1;
}

/**
	 * 生成 10 个人一天的通话记录
	 * 每行中 列中存储 100 条通话记录
	 *
	 */
	@Test
	public void addPhoneRecord3() throws Exception{
		List<Put> puts = new ArrayList<>();
		for(int i = 0;i < 10;i++){
			String phoneNum = generatePhoneNumber("189");
			String rowkey = phoneNum+"_"+(Long.MAX_VALUE-sdf.parse(getDate2("20190801")).getTime());
			Phone.dayPhoneDetail.Builder dayPhoneDetail = Phone.dayPhoneDetail.newBuilder();
			for(int j = 0;j < 100;j++){
				String dnum = generatePhoneNumber("138");
				String length = r.nextInt(99)+""; // 通话时长
				String type = r.nextInt(2)+""; // 1 是主叫，2 是被叫
				String dataStr  = getDate("2019");  // 通话开始时间
				PhoneDetail.Builder phoneDetail = Phone.PhoneDetail.newBuilder();
				phoneDetail.setDnum(dnum);
				phoneDetail.setLength(length);
				phoneDetail.setType(type);
				phoneDetail.setDatastr(dataStr);
				dayPhoneDetail.addPhoneDetail(phoneDetail);
			}
			Put put = new Put(rowkey.getBytes());
			put.add("cf".getBytes(),"day".getBytes(),dayPhoneDetail.build().toByteArray());
			puts.add(put);
		}
		htable.put(puts);
	}
	
	/**
	 * 查看数据
	 * @throws IOException
	 */
	@Test
	public void getData() throws IOException{
		Get get = new Get("18962786962_9223370472247815807".getBytes());
		Result result = htable.get(get);
		Cell cell = result.getColumnLatestCell("cf".getBytes(), "day".getBytes());
		dayPhoneDetail dayPhoneDetail = Phone.dayPhoneDetail.parseFrom(CellUtil.cloneValue(cell));
		List<PhoneDetail> phoneDetailList = dayPhoneDetail.getPhoneDetailList();
		int count = 0;
		for (PhoneDetail pd : phoneDetailList) {
			System.out.println(pd.getDnum()+"\t"+pd.getType()+"\t"+pd.getLength()+"\t"+pd.getDatastr());
			count ++;
		}
		System.out.println("count:"+count);
	}
```

## HBase 优化

### 表设计

- **Region 切分**

  在表设计时，预先估计表中的数据，并切分多个 region，防止数据过多，导致单个服务器过载。

  Region 是按照 Rowkey 来切分的

- **Rowkey 设计**

  Rowkey 按照字典序排列（即 ASCII ）。Rowkey 的长度不要太长，符合业务需求即可。

- **ColumnFamily 设计**

  列族控制在 1~2 之间，不要超过 3 个列族

- **InMemory**

  HBase  中缓存分为写缓存和读缓存。通过 `HColumnDescriptor.setInMemory(true)` 将表放到RegionServer的缓存中，保证在读取的时候被cache命中。

- **<font color='red' size='3px'>compact  & split</font>**

  在 HBase 中，数据在更新时首先写入 WAL 日志(HLog)和内存(MemStore)中，MemStore 中的数据是排序的，当 MemStore 累计到一定阈值时，就会创建一个新的 MemStore，并且将老的 MemStore 添加到 flush队列，由单独的线程 flush 到磁盘上，成为一个 StoreFile 。于此同时， 系统会在 zookeeper 中记录一个 redo point，表示这个时刻之前的变更已经持久化了(minor compact)。
  **StoreFile 是只读的**，一旦创建后就不可以再修改。因此 Hbase 的更新其实是不断追加的操作。当一个 Store中的 StoreFile 达到一定的阈值后，就会进行一次合并(major compact)，将对同一个 key 的修改合并到一起，形成一个大的 StoreFile，当 StoreFile 的大小达到一定阈值后，又会对 StoreFile进行分割(split)，等分为两个StoreFile。
  由于对表的更新是不断追加的，处理读请求时，需要访问Store中全部的StoreFile和MemStore，将它们按照row key进行合并，由于StoreFile和MemStore都是经过排序的，并且StoreFile带有内存中索引，通常合并过程还是比较快的。
  实际应用中，可以考虑必要时手动进行major compact，将同一个row key的修改进行合并形成一个大的StoreFile。同时，可以将StoreFile设置大些，减少split的发生。

  hbase为了防止小文件（被刷到磁盘的menstore）过多，以保证保证查询效率，hbase需要在必要的时候将这些小的store file合并成相对较大的store file，这个过程就称之为compaction。在hbase中，主要存在两种类型的compaction：minor  compaction和major compaction。
  minor compaction:的是较小、很少文件的合并。
  major compaction 的功能是将所有的store file合并成一个，触发major compaction的可能条件有：major_compact 命令、majorCompact() API、region server自动运行（相关参数：hbase.hregion.majoucompaction 默认为24 小时、hbase.hregion.majorcompaction.jetter 默认值为0.2 防止region server 在同一时间进行major compaction）。
  hbase.hregion.majorcompaction.jetter参数的作用是：对参数hbase.hregion.majoucompaction 规定的值起到浮动的作用，假如两个参数都为默认值24和0,2，那么major compact最终使用的数值为：19.2~28.8 这个范围。

  1、关闭自动major compaction
  2、手动编程major compaction
  Timer类，contab
  minor compaction的运行机制要复杂一些，它由一下几个参数共同决定：
  hbase.hstore.compaction.min :默认值为 3，表示至少需要三个满足条件的store file时，minor compaction才会启动
  hbase.hstore.compaction.max 默认值为10，表示一次minor compaction中最多选取10个store file
  hbase.hstore.compaction.min.size 表示文件大小小于该值的store file 一定会加入到minor compaction的store file中
  hbase.hstore.compaction.max.size 表示文件大小大于该值的store file 一定会被minor compaction排除
  hbase.hstore.compaction.ratio 将store file 按照文件年龄排序（older to younger），minor compaction总是从older store file开始选择
  	

### 写表操作

1. **多 Table 并发写**

  创建多个HTable客户端用于写操作，提高写数据的吞吐量，一个例子：

  ```java
  static final Configuration conf = HBaseConfiguration.create();
  static final String table_log_name = “user_log”;
  wTableLog = new HTable[tableN];
  for (int i = 0; i < tableN; i++) {
      wTableLog[i] = new HTable(conf, table_log_name);
      wTableLog[i].setWriteBufferSize(5 * 1024 * 1024); //5MB
      wTableLog[i].setAutoFlush(false);
  }
  ```

2. **HTable 参数设置：**

    - Auto Flush 

      通过调用HTable.setAutoFlush(false)方法可以将HTable写客户端的自动flush关闭，这样可以批量写入数据到HBase，而不是有一条put就执行一次更新，只有当put填满客户端写缓存时，才实际向HBase服务端发起写请求。默认情况下auto flush是开启的。

    - Write Buffer

      通过调用HTable.setWriteBufferSize(writeBufferSize)方法可以设置HTable客户端的写buffer大小，如果新设置的buffer小于当前写buffer中的数据时，buffer将会被flush到服务端。其中，writeBufferSize的单位是byte字节数，可以根据实际写入数据量的多少来设置该值。

    - WAL  Flag

      在HBae中，客户端向集群中的RegionServer提交数据时（Put/Delete操作），首先会先写WAL（Write Ahead Log）日志（即HLog，一个RegionServer上的所有Region共享一个HLog），只有当WAL日志写成功后，再接着写MemStore，然后客户端被通知提交数据成功；如果写WAL日志失败，客户端则被通知提交失败。这样做的好处是可以做到RegionServer宕机后的数据恢复。

      因此，对于相对不太重要的数据，可以在Put/Delete操作时，通过调用Put.setWriteToWAL(false)或Delete.setWriteToWAL(false)函数，放弃写WAL日志，从而提高数据写入的性能。

      **值得注意的是：谨慎选择关闭WAL日志，因为这样的话，一旦RegionServer宕机，Put/Delete的数据将会无法根据WAL日志进行恢复。**

3.  **批量写**

    通过调用HTable.put(Put)方法可以将一个指定的row key记录写入HBase，同样HBase提供了另一个方法：通过调用HTable.put(List<Put>)方法可以将指定的row key列表，批量写入多行记录，这样做的好处是批量执行，只需要一次网络I/O开销，这对于对数据实时性要求高，网络传输RTT高的情景下可能带来明显的性能提升。

4. 多线程并发写

    在客户端开启多个HTable写线程，每个写线程负责一个HTable对象的flush操作，这样结合定时flush和写buffer（writeBufferSize），可以既保证在数据量小的时候，数据可以在较短时间内被flush（如1秒内），同时又保证在数据量大的时候，写buffer一满就及时进行flush。下面给个具体的例子：

    ```java
    for (int i = 0; i < threadN; i++) {
        Thread th = new Thread() {
            public void run() {
                while (true) {
                    try {
                        sleep(1000); //1 second
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
    synchronized (wTableLog[i]) {
                        try {
                            wTableLog[i].flushCommits();
                        } catch (IOException e) {
                            e.printStackTrace();
                        }
                    }
                }
    }
        };
        th.setDaemon(true);
        th.start();
    }
    ```

    

### 读表操作

1. 多 HTable 并发读

  创建多个HTable客户端用于读操作，提高读数据的吞吐量，一个例子：

  ```
  static final Configuration conf = HBaseConfiguration.create();
  static final String table_log_name = “user_log”;
  rTableLog = new HTable[tableN];
  for (int i = 0; i < tableN; i++) {
      rTableLog[i] = new HTable(conf, table_log_name);
      rTableLog[i].setScannerCaching(50);
  }
  ```

2. HTable 参数设置

  - Scanner Caching
    hbase.client.scanner.caching配置项可以设置HBase scanner一次从服务端抓取的数据条数，默认情况下一次一条。通过将其设置成一个合理的值，可以减少scan过程中next()的时间开销，代价是scanner需要通过客户端的内存来维持这些被cache的行记录。
    有三个地方可以进行配置：1）在HBase的conf配置文件中进行配置；2）通过调用HTable.setScannerCaching(int scannerCaching)进行配置；3）通过调用Scan.setCaching(int caching)进行配置。三者的优先级越来越高。
  -  Scan Attribute Selection
    scan时指定需要的Column Family，可以减少网络传输数据量，否则默认scan操作会返回整行所有Column Family的数据。
  -  Close ResultScanner
    通过scan取完数据后，记得要关闭ResultScanner，否则RegionServer可能会出现问题（对应的Server资源无法释放）。
  
3. 批量读

   通过调用HTable.get(Get)方法可以根据一个指定的row key获取一行记录，同样HBase提供了另一个方法：通过调用HTable.get(List<Get>)方法可以根据一个指定的row key列表，批量获取多行记录，这样做的好处是批量执行，只需要一次网络I/O开销，这对于对数据实时性要求高而且网络传输RTT高的情景下可能带来明显的性能提升。

4. 多线程并发读

   在客户端开启多个HTable读线程，每个读线程负责通过HTable对象进行get操作。下面是一个多线程并发读取HBase，获取店铺一天内各分钟PV值的例子：

   ```java
   public class DataReaderServer {
        //获取店铺一天内各分钟PV值的入口函数
        public static ConcurrentHashMap<String, String> getUnitMinutePV(long uid, long startStamp, long endStamp){
            long min = startStamp;
            int count = (int)((endStamp - startStamp) / (60*1000));
            List<String> lst = new ArrayList<String>();
            for (int i = 0; i <= count; i++) {
               min = startStamp + i * 60 * 1000;
               lst.add(uid + "_" + min);
            }
            return parallelBatchMinutePV(lst);
        }
         //多线程并发查询，获取分钟PV值
   private static ConcurrentHashMap<String, String> parallelBatchMinutePV(List<String> lstKeys){
           ConcurrentHashMap<String, String> hashRet = new ConcurrentHashMap<String, String>();
           int parallel = 3;
           List<List<String>> lstBatchKeys  = null;
           if (lstKeys.size() < parallel ){
               lstBatchKeys  = new ArrayList<List<String>>(1);
               lstBatchKeys.add(lstKeys);
           }
           else{
               lstBatchKeys  = new ArrayList<List<String>>(parallel);
               for(int i = 0; i < parallel; i++  ){
                   List<String> lst = new ArrayList<String>();
                   lstBatchKeys.add(lst);
               }
   
               for(int i = 0 ; i < lstKeys.size() ; i ++ ){
                   lstBatchKeys.get(i%parallel).add(lstKeys.get(i));
               }
           }
           
           List<Future< ConcurrentHashMap<String, String> >> futures = new ArrayList<Future< ConcurrentHashMap<String, String> >>(5);
           
           ThreadFactoryBuilder builder = new ThreadFactoryBuilder();
           builder.setNameFormat("ParallelBatchQuery");
           ThreadFactory factory = builder.build();
           ThreadPoolExecutor executor = (ThreadPoolExecutor) Executors.newFixedThreadPool(lstBatchKeys.size(), factory);
           
           for(List<String> keys : lstBatchKeys){
               Callable< ConcurrentHashMap<String, String> > callable = new BatchMinutePVCallable(keys);
               FutureTask< ConcurrentHashMap<String, String> > future = (FutureTask< ConcurrentHashMap<String, String> >) executor.submit(callable);
               futures.add(future);
           }
           executor.shutdown();
           
           // Wait for all the tasks to finish
           try {
             boolean stillRunning = !executor.awaitTermination(
                 5000000, TimeUnit.MILLISECONDS);
             if (stillRunning) {
               try {
                   executor.shutdownNow();
               } catch (Exception e) {
                   // TODO Auto-generated catch block
                   e.printStackTrace();
               }
             }
           } catch (InterruptedException e) {
             try {
                 Thread.currentThread().interrupt();
             } catch (Exception e1) {
               // TODO Auto-generated catch block
               e1.printStackTrace();
             }
           }
           
           // Look for any exception
           for (Future f : futures) {
             try {
                 if(f.get() != null)
                 {
                     hashRet.putAll((ConcurrentHashMap<String, String>)f.get());
                 }
             } catch (InterruptedException e) {
               try {
                    Thread.currentThread().interrupt();
               } catch (Exception e1) {
                   // TODO Auto-generated catch block
                   e1.printStackTrace();
               }
             } catch (ExecutionException e) {
               e.printStackTrace();
             }
           }
           
           return hashRet;
       }
        //一个线程批量查询，获取分钟PV值
       protected static ConcurrentHashMap<String, String> getBatchMinutePV(List<String> lstKeys){
           ConcurrentHashMap<String, String> hashRet = null;
           List<Get> lstGet = new ArrayList<Get>();
           String[] splitValue = null;
           for (String s : lstKeys) {
               splitValue = s.split("_");
               long uid = Long.parseLong(splitValue[0]);
               long min = Long.parseLong(splitValue[1]);
               byte[] key = new byte[16];
               Bytes.putLong(key, 0, uid);
               Bytes.putLong(key, 8, min);
               Get g = new Get(key);
               g.addFamily(fp);
               lstGet.add(g);
           }
           Result[] res = null;
           try {
               res = tableMinutePV[rand.nextInt(tableN)].get(lstGet);
           } catch (IOException e1) {
               logger.error("tableMinutePV exception, e=" + e1.getStackTrace());
           }
   
           if (res != null && res.length > 0) {
               hashRet = new ConcurrentHashMap<String, String>(res.length);
               for (Result re : res) {
                   if (re != null && !re.isEmpty()) {
                       try {
                           byte[] key = re.getRow();
                           byte[] value = re.getValue(fp, cp);
                           if (key != null && value != null) {
                               hashRet.put(String.valueOf(Bytes.toLong(key,
                                       Bytes.SIZEOF_LONG)), String.valueOf(Bytes
                                       .toLong(value)));
                           }
                       } catch (Exception e2) {
                           logger.error(e2.getStackTrace());
                       }
                   }
               }
           }
   
           return hashRet;
       }
   }
   //调用接口类，实现Callable接口
   class BatchMinutePVCallable implements Callable<ConcurrentHashMap<String, String>>{
        private List<String> keys;
   
        public BatchMinutePVCallable(List<String> lstKeys ) {
            this.keys = lstKeys;
        }
   
        public ConcurrentHashMap<String, String> call() throws Exception {
            return DataReadServer.getBatchMinutePV(keys);
        }
   }
   ```

5. 缓存查询

   对于频繁查询HBase的应用场景，可以考虑在应用程序中做缓存，当有新的查询请求时，首先在缓存中查找，如果存在则直接返回，不再查询HBase；否则对HBase发起读请求查询，然后在应用程序中将查询结果缓存起来。至于缓存的替换策略，可以考虑LRU等常用的策略。

6. <font color='red'>BlockCache</font>

   HBase上Regionserver 的内存分为两个部分，一部分作为 Memstore，主要用来写；另外一部分作为BlockCache，主要用于读。

   写请求会先写入Memstore，Regionserver会给每个region提供一个Memstore，当Memstore满64MB以后，会启动 flush刷新到磁盘。当Memstore的总大小超过限制时（heapsize * hbase.regionserver.global.memstore.upperLimit * 0.9），会强行启动flush进程，从最大的Memstore开始flush直到低于限制。

   读请求先到Memstore中查数据，查不到就到BlockCache中查，再查不到就会到磁盘上读，并把读的结果放入BlockCache。由于BlockCache采用的是LRU策略，因此BlockCache达到上限(heapsize * hfile.block.cache.size * 0.85)后，会启动淘汰机制，淘汰掉最老的一批数据。

   一个Regionserver上有一个BlockCache和N个Memstore，它们的大小之和不能大于等于heapsize * 0.8，否则HBase不能启动。默认BlockCache为0.2，而Memstore为0.4。**对于注重读响应时间的系统，可以将** **BlockCache设大些，比如设置BlockCache=0.4，Memstore=0.39，以加大缓存的命中率。**

### HTable 和 HTablePool使用注意事项

HTable和HTablePool都是HBase客户端API的一部分，可以使用它们对HBase表进行CRUD操作。下面结合在项目中的应用情况，对二者使用过程中的注意事项做一下概括总结。

```java
Configuration conf = HBaseConfiguration.create();

try (Connection connection = ConnectionFactory.createConnection(conf)) {

  try (Table table = connection.getTable(TableName.valueOf(tablename)) {

      // use table as needed, the table returned is lightweight

  }

}
```

### HTable

[HTable](http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/HTable.html)是HBase客户端与HBase服务端通讯的Java API对象，客户端可以通过HTable对象与服务端进行CRUD操作（增删改查）。它的创建很简单：

```java
Configuration conf = HBaseConfiguration.create();

HTable table = new HTable(conf, "tablename");

//TODO CRUD Operation……
```

HTable使用时的一些注意事项：

1. 规避 HTable 对象的创建开销
   因为客户端创建 HTable 对象后，需要进行一系列的操作：检查.META.表确认指定名称的HBase表是否存在，表是否有效等等，整个时间开销比较重，可能会耗时几秒钟之长，因此最好在程序启动时一次性创建完成需要的HTable对象，如果使用 Java API，一般来说是在构造函数中进行创建，程序启动后直接重用。

2.   HTable 对象不是线程安全的
HTable 对象对于客户端读写数据来说不是线程安全的，因此多线程时，要为每个线程单独创建复用一个HTable 对象，不同对象间不要共享HTable对象使用，特别是在客户端auto flash被置为false时，由于存在本地write buffer，可能导致数据不一致。
3.   HTable对象之间共享Configuration
HTable对象共享Configuration对象，这样的好处在于：
- 共享ZooKeeper的连接：每个客户端需要与ZooKeeper建立连接，查询用户的table regions位置，这些信息可以在连接建立后缓存起来共享使用；
- 共享公共的资源：客户端需要通过ZooKeeper查找-ROOT-和.META.表，这个需要网络传输开销，客户端缓存这些公共资源后能够减少后续的网络传输开销，加快查找过程速度。

因此，与以下这种方式相比：

```java
HTable table1 = new HTable("table1");

HTable table2 = new HTable("table2");
```

下面的方式更有效些：

```java
Configuration conf = HBaseConfiguration.create();

HTable table1 = new HTable(conf, "table1");

HTable table2 = new HTable(conf, "table2");
```

备注：即使是高负载的多线程程序，也并没有发现因为共享Configuration而导致的性能问题；如果你的实际情况中不是如此，那么可以尝试不共享Configuration。

### HTablePool

[HTablePool](http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/HTablePool.html)可以解决HTable存在的线程不安全问题，同时通过维护固定数量的HTable对象，能够在程序运行期间复用这些HTable资源对象。

```java
Configuration conf = HBaseConfiguration.create();

HTablePool pool = new HTablePool(conf, 10);
```



1. HTablePool可以自动创建HTable对象，而且对客户端来说使用上是完全透明的，可以避免多线程间数据并发修改问题。

2. HTablePool中的HTable对象之间是公用Configuration连接的，能够可以减少网络开销。

HTablePool的使用很简单：每次进行操作前，通过HTablePool的getTable方法取得一个HTable对象，然后进行put/get/scan/delete等操作，最后通过 HTablePool 的 putTable 方法将HTable对象放回到HTablePool中。

下面是个使用HTablePool的简单例子：



```
public void createUser(String username, String firstName, String lastName, String email, String password, String roles) throws IOException {

　　HTable table = rm.getTable(UserTable.NAME);

　　Put put = new Put(Bytes.toBytes(username));

　　put.add(UserTable.DATA_FAMILY, UserTable.FIRSTNAME,

　　Bytes.toBytes(firstName));

　　put.add(UserTable.DATA_FAMILY, UserTable.LASTNAME,

　　　　Bytes.toBytes(lastName));

　　put.add(UserTable.DATA_FAMILY, UserTable.EMAIL, Bytes.toBytes(email));

　　put.add(UserTable.DATA_FAMILY, UserTable.CREDENTIALS,

　　　　Bytes.toBytes(password));

　　put.add(UserTable.DATA_FAMILY, UserTable.ROLES, Bytes.toBytes(roles));

　　table.put(put);

　　table.flushCommits();

　　rm.putTable(table);

}
```

 

Hbase和DBMS比较：

查询数据不灵活：

1.  不能使用column之间过滤查询

2. 不支持全文索引。使用solr和hbase整合完成全文搜索。

   a) 使用MR批量读取hbase中的数据，在solr里面建立索引（no  store）之保存rowkey的值。

   b) 根据关键词从索引中搜索到rowkey（分页）

   c) 根据rowkey从hbase查询所有数据

## HBase-MapReduce 整合

```

```

