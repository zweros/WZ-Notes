---
title: 20191028 CDH
date: 2019-10-28
---

[TOC]

## CDH  简介

为什么 在 Hadoop 2.x 中 HDFS 中有 ZKFC 进程，而 yarn 却没有？ 

在 Hadoop 1.x 升级到 Hadoop 2.x 的过程中，考虑到向下兼容的问题，NameNode 进程没有嵌入 ZKFC 中的代码，而另外开辟一个进程 ZKFC 。再者由于 Hadoop 1.x 中没有 yarn 组件，Hadoop 2.x 中才出现的 yarn 组件，所以  yarn 不用考虑向下兼容的问题，即 ResourceManager 进程就直接嵌入 ZKFC 中的代码，只运行一个进程。



### Apache Hadoop 不足之处	

- 版本管理混乱
- 部署过程繁琐、升级过程复杂
- 兼容性差
- 安全性低

### Hadoop 发行版

- Apache Hadoop
- Cloudera’s Distribution Including Apache Hadoop（CDH）
- Hortonworks Data Platform (HDP) 
- MapR
- EMR

### Cloudera's Distribution, including Apache Hadoop

是Hadoop众多分支中的一种，由Cloudera维护，基于稳定版本的Apache Hadoop构建

提供了Hadoop的核心

- 可扩展存储
- 分布式计算

基于Web的用户界面

## CDH 框架

### CDH  框架图

Impala 是基于内存计算的，执行  SQL ，速度比 Hive 要快

![](http://img.zwer.xyz/blog/20191028144352.png)

### CDH 的优点

- 版本划分清晰

- 版本更新速度快

- 支持Kerberos安全认证

- 文档清晰

- 支持多种安装方式（Cloudera Manager方式）

### CDH 安装方式

- Cloudera Manager
- Yum
- Rpm
- Tarball

CDH5.4
http://archive.cloudera.com/cdh5/

Cloudera Manager5.4.3：
http://www.cloudera.com/downloads/manager/5-4-3.html

## CDH  安装

### Cloudera Manager 简介

```shell
Server
    管理控制台服务器和应用程序逻辑
    负责软件安装、配置
    启动和停止服务
    管理服务运行的群集
Agent
    安装在每台主机上
    负责启动和停止进程，配置，监控主机
Management Service
	由一组角色组成的服务，执行各种监视、报警和报告功能
Database
Cloudera Repository
Clients
    Admin Console
    API 
```

![](http://img.zwer.xyz/blog/20191028161056.png)



### Cloudera Manager 部署

1. **系统环境准备**

   ```shell
   # 使用 xshell 登录时
   # 不能 open 方式登录，可能会影响后面 ssh 免密
   # 而是采用 ssh 方式登录
   
   ssh 免密钥
   ssh localhost 方式创建本地目录
   
   1、网络配置
   vi /etc/sysconfig/network
   vi /etc/hosts
   
   2、SSH免密钥登录
   ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
   ssh-copy-id
   
   3、防火墙关闭
   service iptables stop
   chkconfig iptables off
   
   4、SELINUX关闭
   setenforce 0
   vi /etc/selinux/config (SELINUX=disabled)
   
   5、安装JDK配置环境变量
   export JAVA_HOME=/usr/java/jdkXXX
   export PATH=$JAVA_HOME/bin:$PATH
   export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
   
   6、安装NTP
   # 获取阿里云
   curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo
   # 更新 yum 缓存
   yum makecache
   yum install -y ntp
   # 设置开机启动 
   chkconfig ntpd on
   # 启动 ntpd 服务
   service ntpd start
   # 设置时间同步
   ntpdate ntp1.aliyun.com
   
   7、安装配置mysql
   yum install -y mysql-server
   GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY '123' WITH GRANT OPTION;
   flush privileges
   
   8、下载第三方依赖包
   yum install -y chkconfig python bind-utils psmisc libxslt zlib sqlite cyrus-sasl-plain cyrus-sasl-gssapi fuse fuse-libs redhat-lsb
   
   ```

   

2. **cloudera Manager 安装**

   > 集群分发时，一定要先分发，后启动

   |  HOST  |     node06      |     node07      |     node08      |
   | :----: | :-------------: | :-------------: | :-------------: |
   |   IP   | 192.168.170.106 | 192.168.170.107 | 192.168.170.108 |
   | Server |        *        |                 |                 |
   | Agent  |        *        |        *        |        *        |
   
   ```shell
   1、安装Cloudera Manager Server、Agent
   mkdir /opt/cloudera-manager # (node06,node07,node08) 
   tar xvzf cloudera-manager*.tar.gz -C /opt/cloudera-manager
   
   2、创建用户cloudera-scm # (node06,node07,node08) 
   useradd --system --no-create-home --shell=/bin/false --comment "Cloudera SCM User" cloudera-scm
   
   3、配置CM Agent # (node06)
   修改文件/opt/cloudera-manager/cm-5.4.3/etc/cloudera-scm-agent/config.ini中server_host
   
   4、配置CM Server数据库 # (node06)
   拷贝mysql jar文件到目录 /usr/share/java/
   注意jar包名称要修改为mysql-connector-java.jar
   
   # node06
   grant all on *.* to 'temp'@'%' identified by 'temp' with grant option;
   cd /opt/cloudera-manager/cm-5.4.3/share/cmf/schema/
   ./scm_prepare_database.sh mysql temp -h node06 -utemp -ptemp --scm-host node06 scm scm scm
   格式：数据库类型、数据库、数据库服务器、用户名、密码、cm server服务器
   
   Server节点 #（node06）
   mkdir -p /opt/cloudera/parcel-repo
   chown cloudera-scm:cloudera-scm /opt/cloudera/parcel-repo
   Agent节点 #  (node06,node07,node08) 
   mkdir -p /opt/cloudera/parcels
   chown cloudera-scm:cloudera-scm /opt/cloudera/parcels
   
   6、制作CDH本地源 #（node06）
   下载好文件CDH-5.4.0-1.cdh5.4.0.p0.27-el6.parcel以及manifest.json，将这两个文件放到server节点的/opt/cloudera/parcel-repo下。
   打开manifest.json文件，里面是json格式的配置，找到与下载版本相对应的hash码，新建文件，文件名与你的parel包名一致，并加上.sha后缀，将hash码复制到文件中保存。
   
   7、分发
   cd /opt/cloudera-manager/  
   scp -r ./*  root@node07:`pwd`
   scp -r ./*  root@node08:`pwd`
   
   8、启动CM Server、Agent
   cd /opt/cloudera-manager/cm-5.4.3/etc/init.d/
   ./cloudera-scm-server start
   Sever首次启动会自动创建表以及数据，不要立即关闭或重启，否则需要删除所有表及数据重新安装
   ./cloudera-scm-agent start
   
   
   ```

小技巧： 1. 若运行某个指令执行任务阻塞当前 shell 窗口，且想中断运行该任务，若 `Ctrl + C `不能中断停止，可使用 `Ctrl + Z` 将当前任务放到后台进行，从而不阻塞当前  shell 窗口，然后输入 `jobs -l`，显示当前任务作业的状态及进程号，由 `kill -9 进程号`，强制终止任务作业 2. `netstat -natp |grep 进程号`,查看某个进程使用的端口号



3. 访问 Clouder-manager 的 web 界面

   ```
   访问：http://ManagerHost:7180，
   用户名、密码：admin
   若可以访问，则CM安装成功。
   ```

4. 为什么集群个数更倾向于奇数个，而不是偶数个？

   ```
   以 3 台集群和 4 台集群举例：
   3 台集群，若其中有一台宕机了，3 / 2 = 1.5 < 2,达到了过半的条件，集群可以运行。
   4 台集群，若其中有一台宕机了，4 / 2 = 2 < 3,达到了过半的条件，集群也可以运行。
   但是4 台主机集群和 3台主机集群却承担相同的风险，且成本 4 台主机集群的成本比 3 台主机集群的成本高
   
   举例，若 4 台主机集群中，宕机了 2 台，剩余 2 台，不满足集群主机数量过分的条件，就不保证了集群的数据一致性，进而集群的可用性。同样 3 台主机集群中，宕机了 2台，剩余 1台，也满足集群主机数量过半的条件，即  4 台主机集群和 3台主机集群却承担相同的风险。
   
   说明： 集群中主机数量过半才能正常运行，因为集群中的网络条件等其他因素，可能会出现某台主机在一定时间内不能接受到或者发送消息，所以以集群中主机数量过半作为条件，是较为合理的。
   
   ```


## Hue

> Hue是一个开源的Apache Hadoop UI系统。
>
> 通过使用Hue我们可以在浏览器端的Web控制台上与Hadoop集群进行交互来分析处理数据。
> 例如操作HDFS上的数据、运行Hive脚本、管理Oozie任务等等。
>
> 是基于Python Web框架Django实现的。
>
> 支持任何版本Hadoop

Hue 的特点：
基于文件浏览器（File Browser）访问HDFS
基于web编辑器来开发和运行Hive查询
支持基于Solr进行搜索的应用，并提供可视化的数据视图，报表生成
通过web调试和开发impala交互式查询
spark调试和开发
Pig开发和调试
oozie任务的开发，监控，和工作流协调调度
Hbase数据查询和修改，数据展示
Hive的元数据（metastore）查询
MapReduce任务进度查看，日志追踪
创建和提交MapReduce，Streaming，Java job任务
Sqoop2的开发和调试
Zookeeper的浏览和编辑
数据库（MySQL，PostGres，SQlite，Oracle）的查询和展示

## ClouderaManager 使用 impala_oozie

### ClouderManager 功能使用

主机  - host
机架  - rack
集群  -  Cluster 
服务  - service
服务实例  - service instance
角色  - role
角色实例  - role instance
角色组  - role group
主机模板  - host template
parcel 
静态服务池  - static service pool
动态资源池  - dynamic resource pool

1、集群管理
	添加、删除集群
	启动、停止、重启集群
	重命名集群
	全体集群配置
	移动主机

2、主机管理
	查看主机详细
	主机检查
	集群添加主机
	分配机架
	主机模板
	维护模式
	删除主机

3、服务管理
	添加服务
	对比不同集群上的服务配置
	启动、停止、重启服务
	滚动重启
	终止客户端正在执行的命令
	删除服务
	重命名服务
	配置最大进程数
rlimit_fds

4、角色管理
	角色实例
    添加角色实例
    启动、停止、重启角色实例
    解除授权
    重新授权
    删除角色实例
	角色组
    创建角色组
    管理角色组

5、资源管理
	动态资源池
	静态服务池

6、用户管理

7、安全管理

### 安装 Hive 

> 图形化操作

中间要 Hive 在关系型数据库建立表，并授权

```sql
create database hive     DEFAULT CHARACTER SET utf8;
grant all on hive.* TO 'hive'@'%' IDENTIFIED BY 'hive';
```

### 安装 OOZIE 

> 同样图形化操作

中间要为 OOZIE 在关系型数量库建立库，并授权

```sql
create database oozie     DEFAULT CHARACTER SET utf8;
grant all on oozie.* TO 'oozie'@'%' IDENTIFIED BY 'oozie';
```

### 安装 Hub 

> 图形化操作，点点点...
>
>  小插曲： 什么叫解耦底层技术的平台产品 ？ 直接屏蔽底层的实现

1. Hue 介绍

   代理 HDFS、Hive 、OOIZE 等模块，调用他们的 API ，执行相应的操作，自己只提供了一个 Web 界面，本身并不做什么事情。

2. Hue 的用户模块

   在开始使用 Hue 时，首先要进行登录，登录的用户名和密码，由自己设置。使用 Hue 登录成功后，Hue 会将登录的用户名，告诉给 HDFS ，并在 HDFS 中创建用户家目录。

   注意： 使用 HDFS  只需要用户名，并不需要密码，需要登录的是 Hue 

3. Hue 支持文件修改-仅针对小文件

## Implal

> Cloudera 公司推出，提供对 HDFS 、HBase 数据的高性能、低延迟的交互式 SQL 查询功能
>
> **基于 Hive** 使用**内存计算**，兼顾数据仓库、具有实时、批处理、多并发等特点
>
> 是 CDH 平台首选的 PB 级大数据实时查询分析引擎

### Shuffle  

- MapReduce Shuffle ：

  ​	 首先数据会进行序列化，然后放入环形字节数组缓冲池，当缓冲池达到阈值（默认为 80 M）后，会触发 spill 溢写操作，将缓冲池中的数据写入磁盘文件中，在过程中，会先进行二次排序、分区等操作。若相同的 key 的文件数量达到三个以上，触发 combiner 操作（归并排序），合并文件。注意： 若相同的 key 文件，spill 溢写二次产生二个文件，但不会执行 combiner 操作。从中得出：MapReduce 不能将相同的 key 文件归并到一个文件中，进而得出，MapReduce 写的时候必须采用**二次排序的机制来分区有序，且分区里 key 有序（邻接排列在一起）， 才能够保证MapReduce 的原语（相同的 key 为一组，方法内迭代这一组数据)。**

  MapReduce Shuffile 消耗的计算资源较多，二次排序不可避免

- Spark Shuffle：

  rpartition ： 重新分区  ....

### Implal  架构图

- Implal 启动后会加载 Hive 的 MeataStore 元数据

- Implal 运行速度比 Hive 快的多

- Implal 创建元数据会持久化到 Hive 中

  ​	Hive 为 Implal 做元数据持久化的操作，而 Hive 的元数据存放在关系型数据库中（MySQL、Oracle 中）

![](http://img.zwer.xyz/blog/20191029193806.png)

### 安装 Implal

Catalog Server 安装在 node06 机器上

StateStore 安装在 node06 机器上

Daemon 安装在 node07、node08 机器上

![](http://img.zwer.xyz/blog/20191029201029.png)

### Impala 使用

> Impala 的使用 SQL 与 Hive 的使用类似，但是不支持 Hive 一些特殊操作，如： UDF等。

```shell
使用  impala-shell 打开,进入 impala 交互界面
show tables; 
refresh <tablename> 增量刷新元数据库
invalidate metadata 全量刷新元数据库，将 Hive 的元数据同步刷新到 impala
explain <sql>  显示查询执行计划，步骤
shell <shell> 不退出 impala—shell ,执行  Linux 命令
profile (查询完成后执行）查询最近一次查询的底层信息,[事后诸葛亮]


impala-shell -p  显示 sql 计划
impala-shell -i  host 登录指定 impala
impala-shell -q sql(语句) 不进入交互界面
-B  去掉格式化的样式
-f  sql 文件的位置
-o  输出文件
-c  查询失败后继续执行




```

压缩数据文件的好处: 

1. 节省空间开销
2. 由于数据文件压缩后，体积变小，进入内存速度变快，因为 IO 小了。

### Impala 与 HBase 整合

> 与 Hive 和 HBase 整合类似

## OOZIE 

> 分布式调度

Oozie 是用于 Hadoop 平台的开源的工作流调度引擎

用来管理 Hadoop 作业

属于 web 应用程序，由 Oozie Client 和 Oozie Server  两个组件构成。

Oozie Server 运行于 Java Servlet 容器（tomcat） 中的 web 程序

官网： https://oozie.apache.org

作用： 一组任务使用一个 DAG（有向无环图） 来表示

### Oozie 使用

Oozie 启动成功后，打开 Web 的 UI 界面 

![](http://img.zwer.xyz/blog/20191029215514.png)

解决方法：

- 下载 http://archive.cloudera.com/gplextras/misc/ext-2.2.zip 

```shell
unzip  ext-2.2.zip -d  /var/lib/oozie
```

- 修改 配置 Configuration，保存，重新启动 Oozie

  ![](http://img.zwer.xyz/blog/20191029215621.png)
  

### job.properties

```shell
nameNode=hdfs://node06:8020
jobTracker=node01:8032
queueName=default
exampleRoot=examples

oozie.wf.application.path=${nameNode}/user/
```

![](http://img.zwer.xyz/blog/20191029220808.png)



###   workflow.xml 

```xml
<workflow-app xmlns="uri:oozie:workflow:0.3" name="shell-wf">
	<start to="shell-node"/>
	<action name="shell-node">
		<shell xmlns="uri:oozie:shell-action:0.1">
    		<job-tracker>${jobTracker}</job-tracker>                         
			<name-node><${nameNode}</name-node>
			<configuration>
	        	<property>	
                   		<name>mapred.job.queue.name</name>
						<value>${queueName}</value>
				</property>
			</configuration>
			<exec>echo</exec>
			<argument>hi shell in oozie</argument>
		</shell>
		<ok to="end"/>
        <error to="fail"/>
	</action>
	<kill name="fail">
		<message>
			Map/Reduce failed, error message [${wf:errorMessgae(wf:lastErrorNode())}]
		</message>
	</kill>
	<end name="end" />
</workflow-app>
```

![](http://img.zwer.xyz/blog/20191029220402.png)



  

  