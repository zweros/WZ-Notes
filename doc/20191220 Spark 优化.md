---
title: 20191220 Spark 优化
date: 2019-12-20
---

## Spark优化

## 1 资源优化

### 搭建集群

```shell
在Spark安装路径下 spark/conf/spark-env.sh配置：
SPARK_WORKER_CORES=XXX
SPARK_WORKER_MEMORY=XXX
```

### 提交任务

```shell
提交任务命令，最好使用脚本化提交，可以在提交任务时，给当前Spark 应用程序足够的资源，提交命令：

./spark-submit –master spark://mynode1:7077 –class …. jar …

可以在—master 之后，在—class之前指定如下参数：

 --driver-cores :指定Driver端使用的core数。

 --driver-memory:指定Driver端使用的内存数，如果Driver端有回收数据广播的时候，可以多申请内存。

 --executor-cores：指定Executor端使用的core数，一个core可以某个时刻并行执行1个task，Executor 的core越多代表可以并行执行的task越多。

 --executor-memory:指定Executor端使用的内存，如果shuffle量多、对RDD持久化多、task创建对象多，可以申请多一些内存。

 --total-executor-cores：Standalone集群中，指定当前Spark应用程序最多使用多少core。在Standalone集群中默认提交一个Spark应用程序，这个Spark应用程序会使用当前集群所有的资源。

 --num-executor：在Yarn集群中默认为一个提交的Spark应用程序启动几个Executor，默认启动2个。

除了以上提交任务时可以指定参数外，也可以在代码中设置（不建议）：SparkConf.set(k,v)在代码中这种方式设置。也可以在Spark提交任务的客户端的spark/conf/spark-defauts.xml(不建议)下配置以下参数：

spark.driver.cores

spark.driver.memory

spark.exeuctor.cores

spark.executor.memory

spark.cores.max
```



## 2 提高并行度

```scala
SparkContext.textFile(xx,minnum)

SparkContext.parallelize(xx,num)

SparkContext.makeRDD(xx，num)

SparkContext.parallelizePairs(List<Tuple2<xx,xx>>,num)

 RDD的算子repartition(num)/coalesce(num)、reduceByKey(num)、join(num)、groupByKey(num)、distinct(num)

 “spark.default.parallelism” Spark中默认的并行度

 自定义分区器也可以增加并行度

“spark.sql.shuffle.partitions”设置SparkSQL中解析成SparkJob的并行度。

SparkStreaming中Direct模式可以增大读取的topic的partition个数。

【不用】SparkStreaming中Receiver模式可以调节参数“spark.streaming.blockInterval”=200ms ，可以减少这个参数，提高并行度，最小不能低于50ms。
```

### 自定义分区器

```scala
package com.szxy.myscalacode

import org.apache.spark.rdd.RDD
import org.apache.spark.{Partitioner, SparkConf, SparkContext}


import scala.collection.mutable.ListBuffer

/**
 * 自定义分区器
 */
object SellfDefinedPartition {
  def main(args: Array[String]): Unit = {
    val conf: SparkConf = new SparkConf().setMaster("local").setAppName("test")
    val rdd: RDD[(String, Int)] = new SparkContext(conf).parallelize(Array[(String, Int)](
      "zhangsan" -> 1, "lisi" -> 2, "wangwu" -> 3,
          "tianqi" -> 4, "zhaoliu" -> 5, "xiaojiu" -> 6
    ), 3)

    println(s"nums of partitions is ${rdd.getNumPartitions}")

    val rddSwap: RDD[(Int, String)] = rdd.map(_.swap)

    rddSwap.mapPartitionsWithIndex((index,iter)=>{
      val list: ListBuffer[(String)] = new ListBuffer[(String)]()
      while(iter.hasNext){
        val tuple: (Int, String) = iter.next()
        list.append(s"index = ${index}, key = ${tuple._1} , value = ${tuple._2}")
      }
      list.iterator
    }).foreach(println)

    /**
     * 自定义分区器，可以提高并行度
     */
    val rdd2: RDD[(Int, String)] = rddSwap.partitionBy(new Partitioner() {
      // 分区数
      override def numPartitions: Int = 6

      // 自定义分区策略
      override def getPartition(key: Any): Int = key.toString.toInt % numPartitions
    })

    rdd2.mapPartitionsWithIndex((index,iter)=>{
      val list: ListBuffer[(String)] = new ListBuffer[(String)]()
      while(iter.hasNext){
        val tuple: (Int, String) = iter.next()
        list.append(s"index = ${index}, key = ${tuple._1} , value = ${tuple._2}")
      }
      list.iterator
    }).foreach(println)

  }
}
```



## 3 代码优化

 ### 避免创建重复的RDD

这种情况为了避免某些代码逻辑不执行。逻辑混乱。

 对多次使用的RDD持久化

持久化的算子：cache() 、persist()，持久化单位Partition

常用的持久化级别：cache()=persist()=persist(StroageLevel.MEMORY_ONLY)

如果内存够用可以使用MEMORY_ONLY级别，如果内存不是太充足，可以采用MEMORY_ONLY_SER级别，相当于牺牲性能换取空间。如果使用MEMORY_ONLY-SER级别还是不能使用数据完全存储，可以使用MEMORY_AND_DISK或者MEMORY_AND_DISK_SER。

注意：对RDD进行持久化时，一定要使用Action触发，这个RDD才能被持久化。

### 尽量避免使用shuffle类的算子

广播变量+map类的算子 代替Join。

 尽量使用map端有预聚合（map-combine）的算子

map端预聚合的好处：

1) 减少map端shuffle落地数据量

2) 减少reduce端拉取的数据量

3) 减少节点之间传输的数据量

map端预聚合的算子有以下几个：

1) reduceByKey

2) aggregateByKey

```scala
object AggregateByKeyTest {
  def main(args: Array[String]): Unit = {
    val conf: SparkConf = new SparkConf().setMaster("local[2]").setAppName("AggregateByKeyTest")
    val sc: SparkContext = new SparkContext(conf)
    val nameNum2RDD: RDD[(String, Int)] = sc.parallelize(Array[(String, Int)](
      ("zhangsan", 18),
      ("zhangsan", 19),
      ("wangwu", 17),
      ("lisi", 20),
      ("wangwu", 25),
      ("lisi", 27)
    ),3)

    nameNum2RDD.mapPartitionsWithIndex((index, iter)=>{
      while(iter.hasNext){
        val next: (String, Int) = iter.next()
        println(s"index=${index}, key=${next._1} value=${next._2}")
      }
      iter.toIterator
    }).count()

    // 使用 AggregateByKey 算子
    val result: RDD[(String, String)] = nameNum2RDD.aggregateByKey("Hello")((v: String, i: Int) => {
      v + "#" + i
    }, (s1: String, s2: String) => {
      s1 + "@" + s2
    })
    result.foreach(println)

  }
}
```

3) combineByKey

```scala
object CombinerByKeyTest {
  def main(args: Array[String]): Unit = {
    val conf: SparkConf = new SparkConf().setMaster("local[2]").setAppName("AggregateByKeyTest")
    val sc: SparkContext = new SparkContext(conf)
    val nameNum2RDD: RDD[(String, Int)] = sc.parallelize(Array[(String, Int)](
      ("zhangsan", 18),
      ("zhangsan", 18),
      ("wangwu", 17),
      ("lisi", 20),
      ("wangwu", 25),
      ("lisi", 27)
    ),3)

    nameNum2RDD

    val result: RDD[(String, String)] = nameNum2RDD.combineByKey((i: Int) => {
      "Hello" + i
    }, (s: String, v: Int) => {
      s + "#" + v
    }, (s1: String, s2: String) => {
      s1 + "@" + s2
    })

    result.foreach(println)

  }
}
```

 ### 使用高性能的算子

1) 使用 `reduceByKey` 代替 `groupByKey`

2) 使用 `mapPartitions`代替 `map`

3) 使用 `foreachPartitions` 代替 `foreach`

4) 对RDD大量过滤数据之后使用 `repartition/coalesce` 减少分区

5) `mapPattitionsToPair/flatMapPartitions`

### 使用广播变量

如果Executor端使用到了Driver端的变量副本，如果不使用广播变量在每个Executor端有多少task就有多少Driver端的变量副本。

如果使用广播变量，在每个Executor中只有一份Driver端的变量副本。发送到某个Executor的task公用这一份广播变量。可以节省Executor端的大量内存。

### 优化数据结构

在编写Spark的代码时，尽量保持以下三个原则：

1) 尽量使用原生的数据类型代替字符串。

2) 尽量使用字符串代替对象。

3) 尽量使用数组代替Map集合。

###  使用Kryo序列化方式

在Spark中，主要有三个地方涉及到了序列化：

1) 在算子函数中使用到外部变量时，该变量会被序列化后进行网络传输。

2) 将自定义的类型作为RDD的泛型类型时（比如`JavaRDD<SXT>`，SXT是自定义类型），所有自定义类型对象，都会进行序列化。因此这种情况下，也要求自定义的类必须实现Serializable接口。

3) 使用可序列化的持久化策略时（比如MEMORY_ONLY_SER），Spark会将RDD中的每个partition都序列化成一个大的字节数组。

Kryo序列化器介绍：

Spark支持使用Kryo序列化机制。Kryo序列化机制，比默认的Java序列化机制，速度要快，序列化后的数据要更小，大概是Java序列化机制的1/10。所以Kryo序列化优化以后，可以让网络传输的数据变少；在集群中耗费的内存资源大大减少。 

对于这三种出现序列化的地方，我们都可以通过使用Kryo序列化类库，来优化序列化和反序列化的性能。Spark默认使用的是Java的序列化机制，也就是ObjectOutputStream/ObjectInputStream API来进行序列化和反序列化。但是Spark同时支持使用Kryo序列化库，Kryo序列化类库的性能比Java序列化类库的性能要高很多。官方介绍，Kryo序列化机制比Java序列化机制，性能高10倍左右。Spark之所以默认没有使用Kryo作为序列化类库，是因为Kryo要求最好要注册所有需要进行序列化的自定义类型，因此对于开发者来说，这种方式比较麻烦。

Spark中使用Kryo：

```scala
SparkConf.set("spark.serializer", "org.apache.spark.serializer.KryoSerializer")
 .registerKryoClasses(new Class[]{SpeedSortKey.class})
```

总结以上代码优化，主要在编写代码时减少内存的使用，减少磁盘的IO。

 

## 4 数据本地化调优

数据本地化级别（级别从高往低排列）：

PROCESS_LOCAL > NODE_LOCAL > RACK_LOCAL > ANY

![](http://img.zwer.xyz/blog/wps1.jpg)

 

如何进行数据本地化调节：

![](http://img.zwer.xyz/blog/数据本地化处理2.bmp) 

设置参数：

```shell
# 内存中处理
spark.locality.wait.process  默认为 3s
# 同节点上处理
spark.locality.wait.node   默认为 3s
# 同 rack 机架上处理
spark.locality.wait.rack   默认为 3s
```

以上参数设置值建议是整数倍设置。可以在代码中设置，可以在`spark/conf/spark-defatults.xml `中设置，最好在提交命令时设置。可以从Spark应用程序的WEBUI中查看数据本地化的级别进行调节。

## 5 Shuffle优化

```xml
spark.reducer.maxSizeInFlight 48M
reduce端一次拉取数据的量，可以设置多一些，减少节点之间数据的拉取次数。

spark.shuffle.io.maxRetries 3
task在节点之间拉取数据尝试重试的次数，可以设置多一些，减少由于网络延迟或者数据所在节点Executor JVM 等待GC导致的失败。

spark.shuffle.io.retryWait 5s
task拉取数据默认task失败的等待间隔。

spark.shuffle.sort.bypassMergeThreshold
如果数据shuffle过程中不需要map端的聚合，只是将数据分散，可以使用bypass机制，默认这个参数是200。当Spark应用程序reduce task个数小于等于这个值时才会采用bypass机制，如果reduce task 个数大于这个值，可以设置这个参数大一些，使用bypass机制。
```

## 6 内存调节

![](http://img.zwer.xyz/blog/wps3.jpg) 

在Spark应用程序执行中，内存的调节指的是给task的运行足够的内存。

*如何调节Executor的task运行内存？*

统一内存中，降低 `spark.memory.fraction` 参数值，默认是0.6，如果Spark应用程序中对RDD的缓存要求不高，或者shuffle数据量不大，可以降低这个参数给task运行足够的内存。



## 7  堆外内存调节

Spark底层shuffle的传输方式是使用netty传输，**netty在进行网络传输的过程会申请堆外内存（netty是零拷贝）**，所以使用了堆外内存。默认情况下，这个堆外内存上限默认是每一个executor的内存大小的10%；真正处理大数据的时候，这里都会出现问题，导致spark作业反复崩溃，无法运行；此时就会去调节这个参数，至少1G（1024M），甚至说2G、4G。

executor在进行shuffle write，优先从自己本地关联的mapOutPutWorker中获取某份数据，如果本地block manager没有的话，那么会通过TransferService，去远程连接其他节点上executor的block manager去获取，尝试建立远程的网络连接，并且去拉取数据。频繁创建对象让JVM堆内存满溢，进行垃圾回收。正好碰到那个exeuctor的JVM在垃圾回收。**处于垃圾回过程中，所有的工作线程全部停止**；相当于只要一旦进行垃圾回收，spark / executor停止工作，无法提供响应，spark默认的网络连接的超时时长是60s；如果卡住60s都无法建立连接的话，那么这个task就失败了。task失败了就会出现`shuffle file cannot find`的错误。

那么*如何调节等待的时长呢？*

在./spark-submit提交任务的脚本里面添加：

`--conf spark.core.connection.ack.wait.timeout=300`

Executor由于内存不足或者堆外内存不足了，挂掉了，对应的Executor上面的block manager也挂掉了，找不到对应的shuffle map output文件，Reducer端不能够拉取数据。我们可以调节堆外内存的大小，如何调节？

在` ./spark-submit `提交任务的脚本里面添加

yarn下：

```shell
--conf  spark.yarn.executor.memoryOverhead=2048 单位M
```

standalone下：

```shell
--conf spark.executor.memoryOverhead=2048单位M
```

<img src="http://img.zwer.xyz/blog/wps4.jpg"  /> 

## 8  数据倾斜处理

数据倾斜：

**MR:**

在MapReduce中，某个reduce task处理的数据相对于其他reduce task处理的数据量要大，执行时间很长。

**Hive:**

在Hive中某张表某列下的Key对应数据量相对于其他key来说非常多，后期会使用这张表和其他表按照这个列去关联，解析成的job中有数据倾斜，我们就说这张Hive表有数据倾斜。

**Spark:**

在Spark应用程序中，RDD中某个分区的数据量相对于其他分区数据量大，对应当前处理数据的task执行时间长。在Spark中如果没有shuffle就没有数据倾斜。

**解决数据倾斜的方案：**

1) **使用Hive ETL解决数据倾斜**

方案适用场景：

如果导致数据倾斜的是Hive表。如果该Hive表中的数据本身很不均匀（比如某个key对应了100万数据，其他key才对应了10条数据），而且业务场景需要频繁使用Spark对Hive表执行某个分析操作，那么比较适合使用这种技术方案。

方案实现思路：

此时可以评估一下，是否可以通过Hive来进行数据预处理（即通过Hive ETL预先对数据按照key进行聚合，或者是预先和其他表进行join），然后在Spark作业中针对的数据源就不是原来的Hive表了，而是预处理后的Hive表。此时由于数据已经预先进行过聚合或join操作了，那么在Spark作业中也就不需要使用原先的shuffle类算子执行这类操作了。

方案实现原理：

这种方案从Spark中解决了数据倾斜，因为彻底避免了在Spark中执行shuffle类算子，那么肯定就不会有数据倾斜的问题了。但是这里也要提醒一下大家，这种方式属于治标不治本。因为毕竟数据本身就存在分布不均匀的问题，所以Hive ETL中进行group by或者join等shuffle操作时，还是会出现数据倾斜，导致Hive ETL的速度很慢。*我们只是把数据倾斜的发生提前到了Hive ETL中，避免Spark程序发生数据倾斜而已*。

2) **过滤少数倾斜的key**

方案适用场景：

如果发现导致倾斜的key就少数几个，而且对计算本身的影响并不大的话，那么很适合使用这种方案。比如99%的key就对应10条数据，但是只有一个key对应了100万数据，从而导致了数据倾斜。

方案实现思路：

如果我们判断那少数几个数据量特别多的key，对作业的执行和计算结果不是特别重要的话，那么干脆就直接过滤掉那少数几个key。比如，在Spark SQL中可以使用where子句过滤掉这些key或者在Spark Core中对RDD执行filter算子过滤掉这些key。如果需要每次作业执行时，动态判定哪些key的数据量最多然后再进行过滤，那么可以使用sample算子对RDD进行采样，然后计算出每个key的数量，取数据量最多的key过滤掉即可。

方案实现原理：

将导致数据倾斜的key给过滤掉之后，这些key就不会参与计算了，自然不可能产生数据倾斜。

3) **增加并行度**

方案实现思路：

在对RDD执行shuffle算子时，给shuffle算子传入一个参数，比如reduceByKey(1000)，该参数就设置了这个shuffle算子执行时shuffle read task的数量。对于Spark SQL中的shuffle类语句，比如group by、join等，需要设置一个参数，即spark.sql.shuffle.partitions，该参数代表了shuffle read task的并行度，该值默认是200，对于很多场景来说都有点过小。

方案实现原理：

增加shuffle read task的数量，可以让原本分配给一个task的多个key分配给多个task，从而让每个task处理比原来更少的数据。举例来说，如果原本有5个不同的key，每个key对应10条数据，这5个key都是分配给一个task的，那么这个task就要处理50条数据。而增加了shuffle read task以后，每个task就分配到一个key，即每个task就处理10条数据，那么自然每个task的执行时间都会变短了。

![](http://img.zwer.xyz/blog/wps5.jpg) 

4) **双重聚合方式解决数据倾斜**

方案适用场景：

对RDD执行reduceByKey等聚合类shuffle算子或者在Spark SQL中使用group by语句进行分组聚合时，比较适用这种方案。

方案实现思路：

这个方案的核心实现思路就是进行两阶段聚合。第一次是局部聚合，先给每个key都打上一个随机数，比如10以内的随机数，此时原先一样的key就变成不一样的了，比如(hello, 1) (hello, 1) (hello, 1) (hello, 1)，就会变成(1_hello, 1) (1_hello, 1) (2_hello, 1) (2_hello, 1)。接着对打上随机数后的数据，执行reduceByKey等聚合操作，进行局部聚合，那么局部聚合结果，就会变成了(1_hello, 2) (2_hello, 2)。然后将各个key的前缀给去掉，就会变成(hello,2)(hello,2)，再次进行全局聚合操作，就可以得到最终结果了，比如(hello, 4)。

方案实现原理：

将原本相同的key通过附加随机前缀的方式，变成多个不同的key，就可以让原本被一个task处理的数据分散到多个task上去做局部聚合，进而解决单个task处理数据量过多的问题。接着去除掉随机前缀，再次进行全局聚合，就可以得到最终的结果。

![](http://img.zwer.xyz/blog/wps6.jpg) 

如果一个RDD中有一个key导致数据倾斜，同时还有其他的key，那么一般先对数据集进行抽样，然后找出倾斜的key,再使用filter对原始的RDD进行分离为两个RDD，一个是由倾斜的key组成的RDD1，一个是由其他的key组成的RDD2，那么对于RDD1可以使用加随机前缀进行多分区多task计算，对于另一个RDD2正常聚合计算，最后将结果再合并起来。

5) **将reduce Join转换成map Join**

BroadCast+map类的算子（如：filter）

方案适用场景：

在对RDD使用join类操作，或者是在Spark SQL中使用join语句时，而且join操作中的*一个RDD或表的数据量比较小（比如几百M或者一两G）*，比较适用此方案。

方案实现思路：

不使用join算子进行连接操作，而使用Broadcast变量与map类算子实现join操作，进而完全规避掉shuffle类的操作，彻底避免数据倾斜的发生和出现。将较小RDD中的数据直接通过`collect `算子拉取到Driver端的内存中来，然后对其创建一个Broadcast变量；接着对另外一个RDD执行map类算子，在算子函数内，从Broadcast变量中获取较小RDD的全量数据，与当前RDD的每一条数据按照连接key进行比对，如果连接key相同的话，那么就将两个RDD的数据用你需要的方式连接起来。

方案实现原理：

普通的join是会走shuffle过程的，而一旦shuffle，就相当于会将相同key的数据拉取到一个shuffle read task中再进行join，此时就是reduce join。但是如果一个RDD是比较小的，则可以采用广播小RDD全量数据+map算子来实现与join同样的效果，也就是map join，此时就不会发生shuffle操作，也就不会发生数据倾斜。

6) **采样倾斜key并分拆join操作**

方案适用场景：

两个RDD/Hive表进行join的时候，如果数据量都比较大，无法采用“解决方案5”，那么此时可以看一下两个RDD/Hive表中的key分布情况。如果出现数据倾斜，是因为其中某一个RDD/Hive表中的少数几个key的数据量过大，而另一个RDD/Hive表中的所有key都分布比较均匀，那么采用这个解决方案是比较合适的。

方案实现思路：

对包含少数几个数据量过大的key的那个RDD，通过sample算子采样出一份样本来，然后统计一下每个key的数量，计算出来数据量最大的是哪几个key。然后将这几个key对应的数据从原来的RDD中拆分出来，形成一个单独的RDD，并给每个key都打上n以内的随机数作为前缀，而不会导致倾斜的大部分key形成另外一个RDD。接着将需要join的另一个RDD，也过滤出来那几个倾斜key对应的数据并形成一个单独的RDD，将每条数据膨胀成n条数据，这n条数据都按顺序附加一个0~n的前缀，不会导致倾斜的大部分key也形成另外一个RDD。再将附加了随机前缀的独立RDD与另一个膨胀n倍的独立RDD进行join，此时就可以将原先相同的key打散成n份，分散到多个task中去进行join了。而另外两个普通的RDD就照常join即可。最后将两次join的结果使用union算子合并起来即可，就是最终的join结果	。

![](http://img.zwer.xyz/blog/wps7.jpg) 

7) **直接扩容再Join**

方案适用场景：

如果在进行join操作时，RDD中有大量的key导致数据倾斜，那么进行分拆key也没什么意义，此时就只能使用最后一种方案来解决问题了。

方案七与方案六的区别是方案七没有分拆 key 的过程，而是直接进行一个RDD打上随机前缀，另一个 RDD 膨胀。这样解决数据倾斜会占用的磁盘空间比较大，但是内存占用并不会太大，由于 Spark 采用 pipeline 计算模式，数据一条条进入内存中处理中。

方案实现思路：

该方案的实现思路基本和“解决方案6”类似，首先查看RDD/Hive表中的数据分布情况，找到那个造成数据倾斜的RDD/Hive表，比如有多个key都对应了超过1万条数据。然后将该RDD的每条数据都打上一个n以内的随机前缀。同时对另外一个正常的RDD进行扩容，将每条数据都扩容成n条数据，扩容出来的每条数据都依次打上一个0~n的前缀。最后将两个处理后的RDD进行join即可。

 

 